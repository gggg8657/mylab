{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.018199,
          "end_time": "2020-10-15T08:02:25.152349",
          "exception": false,
          "start_time": "2020-10-15T08:02:25.134150",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#All credits goes to Andrej Karpathy\n",
        "#I **do not** own any of the code below, this is just a notebook for you to play around on Kaggle\n",
        "#github: https://github.com/karpathy/minGPT\n",
        "#Train GPT on images\n",
        "\n",
        "Effectively re-implements OpenAI's Image GPT model, getting GPT to model images instead of text, but using a near identical model. It's truly quite remarkable that a single model can agnostically do a great job modeling whatever data you give it: text, images, or whatever else. At the end of the day it is just a sequence of integers. Notice that unlike models like PixelCNN++ etc, this model knows nothing at all about the spatial layout of the pixels and has to learn the appropriate positional embeddings that reflect the spatial topology of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:25.195295Z",
          "iopub.status.busy": "2020-10-15T08:02:25.194339Z",
          "iopub.status.idle": "2020-10-15T08:02:27.576827Z",
          "shell.execute_reply": "2020-10-15T08:02:27.575670Z"
        },
        "papermill": {
          "duration": 2.407223,
          "end_time": "2020-10-15T08:02:27.577005",
          "exception": false,
          "start_time": "2020-10-15T08:02:25.169782",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:27.628299Z",
          "iopub.status.busy": "2020-10-15T08:02:27.625484Z",
          "iopub.status.idle": "2020-10-15T08:02:27.631633Z",
          "shell.execute_reply": "2020-10-15T08:02:27.632707Z"
        },
        "papermill": {
          "duration": 0.03397,
          "end_time": "2020-10-15T08:02:27.632945",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.598975",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# set up logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:27.705532Z",
          "iopub.status.busy": "2020-10-15T08:02:27.695171Z",
          "iopub.status.idle": "2020-10-15T08:02:27.709086Z",
          "shell.execute_reply": "2020-10-15T08:02:27.708339Z"
        },
        "papermill": {
          "duration": 0.048528,
          "end_time": "2020-10-15T08:02:27.709233",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.660705",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#utils\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def top_k_logits(logits, k):\n",
        "    v, ix = torch.topk(logits, k)\n",
        "    out = logits.clone()\n",
        "    out[out < v[:, [-1]]] = -float('Inf')\n",
        "    return out\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, x, steps, temperature=1.0, sample=False, top_k=None):\n",
        "    \"\"\"\n",
        "    take a conditioning sequence of indices in x (of shape (b,t)) and predict the next token in\n",
        "    the sequence, feeding the predictions back into the model each time. Clearly the sampling\n",
        "    has quadratic complexity unlike an RNN that is only linear, and has a finite context window\n",
        "    of block_size, unlike an RNN that has an infinite context window.\n",
        "    \"\"\"\n",
        "    block_size = model.get_block_size()\n",
        "    model.eval()\n",
        "    for k in range(steps):\n",
        "        x_cond = x if x.size(1) <= block_size else x[:, -block_size:] # crop context if needed\n",
        "        logits, _ = model(x_cond)\n",
        "        # pluck the logits at the final step and scale by temperature\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        # optionally crop probabilities to only the top k options\n",
        "        if top_k is not None:\n",
        "            logits = top_k_logits(logits, top_k)\n",
        "        # apply softmax to convert to probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # sample from the distribution or take the most likely\n",
        "        if sample:\n",
        "            ix = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, ix = torch.topk(probs, k=1, dim=-1)\n",
        "        # append to the sequence and continue\n",
        "        x = torch.cat((x, ix), dim=1)\n",
        "\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:27.785190Z",
          "iopub.status.busy": "2020-10-15T08:02:27.779662Z",
          "iopub.status.idle": "2020-10-15T08:02:27.801252Z",
          "shell.execute_reply": "2020-10-15T08:02:27.801843Z"
        },
        "papermill": {
          "duration": 0.07272,
          "end_time": "2020-10-15T08:02:27.802023",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.729303",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#trainer\n",
        "\"\"\"\n",
        "Simple training loop; Boilerplate that could apply to any arbitrary neural network,\n",
        "so nothing in this file really has anything to do with GPT specifically.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import logging\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TrainerConfig:\n",
        "    # optimization parameters\n",
        "    max_epochs = 10\n",
        "    batch_size = 64\n",
        "    learning_rate = 3e-4\n",
        "    betas = (0.9, 0.95)\n",
        "    grad_norm_clip = 1.0\n",
        "    weight_decay = 0.1 # only applied on matmul weights\n",
        "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
        "    lr_decay = False\n",
        "    warmup_tokens = 375e6 # these two numbers come from the GPT-3 paper, but may not be good defaults elsewhere\n",
        "    final_tokens = 260e9 # (at what point we reach 10% of original LR)\n",
        "    # checkpoint settings\n",
        "    ckpt_path = None\n",
        "    num_workers = 0 # for DataLoader\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, train_dataset, test_dataset, config):\n",
        "        self.model = model\n",
        "        self.train_dataset = train_dataset\n",
        "        self.test_dataset = test_dataset\n",
        "        self.config = config\n",
        "\n",
        "        # take over whatever gpus are on the system\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.cuda.current_device()\n",
        "            self.model = torch.nn.DataParallel(self.model).to(self.device)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        # DataParallel wrappers keep raw model object in .module attribute\n",
        "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
        "        logger.info(\"saving %s\", self.config.ckpt_path)\n",
        "        torch.save(raw_model.state_dict(), self.config.ckpt_path)\n",
        "\n",
        "    def train(self):\n",
        "        model, config = self.model, self.config\n",
        "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
        "        optimizer = raw_model.configure_optimizers(config)\n",
        "\n",
        "        def run_epoch(split):\n",
        "            is_train = split == 'train'\n",
        "            model.train(is_train)\n",
        "            data = self.train_dataset if is_train else self.test_dataset\n",
        "            loader = DataLoader(data, shuffle=True, pin_memory=True,\n",
        "                                batch_size=config.batch_size,\n",
        "                                num_workers=config.num_workers)\n",
        "\n",
        "            losses = []\n",
        "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
        "            for it, (x, y) in pbar:\n",
        "\n",
        "                # place data on the correct device\n",
        "                x = x.to(self.device)\n",
        "                y = y.to(self.device)\n",
        "\n",
        "                # forward the model\n",
        "                with torch.set_grad_enabled(is_train):\n",
        "                    logits, loss = model(x, y)\n",
        "                    loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
        "                    losses.append(loss.item())\n",
        "\n",
        "                if is_train:\n",
        "\n",
        "                    # backprop and update the parameters\n",
        "                    model.zero_grad()\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # decay the learning rate based on our progress\n",
        "                    if config.lr_decay:\n",
        "                        self.tokens += (y >= 0).sum() # number of tokens processed this step (i.e. label is not -100)\n",
        "                        if self.tokens < config.warmup_tokens:\n",
        "                            # linear warmup\n",
        "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
        "                        else:\n",
        "                            # cosine learning rate decay\n",
        "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
        "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "                        lr = config.learning_rate * lr_mult\n",
        "                        for param_group in optimizer.param_groups:\n",
        "                            param_group['lr'] = lr\n",
        "                    else:\n",
        "                        lr = config.learning_rate\n",
        "\n",
        "                    # report progress\n",
        "                    pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "\n",
        "            if not is_train:\n",
        "                test_loss = float(np.mean(losses))\n",
        "                logger.info(\"test loss: %f\", test_loss)\n",
        "                return test_loss\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        self.tokens = 0 # counter used for learning rate decay\n",
        "        for epoch in range(config.max_epochs):\n",
        "\n",
        "            run_epoch('train')\n",
        "            if self.test_dataset is not None:\n",
        "                test_loss = run_epoch('test')\n",
        "\n",
        "            # supports early stopping based on the test loss, or just save always if no test set is provided\n",
        "            good_model = self.test_dataset is None or test_loss < best_loss\n",
        "            if self.config.ckpt_path is not None and good_model:\n",
        "                best_loss = test_loss\n",
        "                self.save_checkpoint()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:27.864846Z",
          "iopub.status.busy": "2020-10-15T08:02:27.848494Z",
          "iopub.status.idle": "2020-10-15T08:02:27.912567Z",
          "shell.execute_reply": "2020-10-15T08:02:27.911796Z"
        },
        "papermill": {
          "duration": 0.09252,
          "end_time": "2020-10-15T08:02:27.912721",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.820201",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#model\n",
        "\"\"\"\n",
        "GPT model:\n",
        "- the initial stem consists of a combination of token encoding and a positional encoding\n",
        "- the meat of it is a uniform sequence of Transformer blocks\n",
        "    - each Transformer is a sequential combination of a 1-hidden-layer MLP block and a self-attention block\n",
        "    - all blocks feed into a central residual pathway similar to resnets\n",
        "- the final decoder is a linear projection into a vanilla Softmax classifier\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GPTConfig:\n",
        "    \"\"\" base GPT config, params common to all GPT versions \"\"\"\n",
        "    embd_pdrop = 0.1\n",
        "    resid_pdrop = 0.1\n",
        "    attn_pdrop = 0.1\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, **kwargs):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.block_size = block_size\n",
        "        for k,v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "\n",
        "class GPT1Config(GPTConfig):\n",
        "    \"\"\" GPT-1 like network roughly 125M params \"\"\"\n",
        "    n_layer = 12\n",
        "    n_head = 12\n",
        "    n_embd = 768\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
        "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
        "    explicit implementation here to show that there is nothing too scary here.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads\n",
        "        self.key = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.query = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.value = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # regularization\n",
        "        self.attn_drop = nn.Dropout(config.attn_pdrop)\n",
        "        self.resid_drop = nn.Dropout(config.resid_pdrop)\n",
        "        # output projection\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "\n",
        "    def forward(self, x, layer_past=None):\n",
        "        B, T, C = x.size()\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        k = self.key(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = self.query(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = self.value(x).view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.mask[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_drop(self.proj(y))\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" an unassuming Transformer block \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.resid_pdrop),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    \"\"\"  the full GPT language model, with a context size of block_size \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # input embedding stem\n",
        "        self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))\n",
        "        self.drop = nn.Dropout(config.embd_pdrop)\n",
        "        # transformer\n",
        "        self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])\n",
        "        # decoder head\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "        self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.block_size = config.block_size\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        logger.info(\"number of parameters: %e\", sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def configure_optimizers(self, train_config):\n",
        "        \"\"\"\n",
        "        This long function is unfortunately doing something very simple and is being very defensive:\n",
        "        We are separating out all parameters of the model into two buckets: those that will experience\n",
        "        weight decay for regularization and those that won't (biases, and layernorm/embedding weights).\n",
        "        We are then returning the PyTorch optimizer object.\n",
        "        \"\"\"\n",
        "\n",
        "        # separate out all parameters to those that will and won't experience regularizing weight decay\n",
        "        decay = set()\n",
        "        no_decay = set()\n",
        "        whitelist_weight_modules = (torch.nn.Linear, )\n",
        "        blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.Embedding)\n",
        "        for mn, m in self.named_modules():\n",
        "            for pn, p in m.named_parameters():\n",
        "                fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
        "\n",
        "                if pn.endswith('bias'):\n",
        "                    # all biases will not be decayed\n",
        "                    no_decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
        "                    # weights of whitelist modules will be weight decayed\n",
        "                    decay.add(fpn)\n",
        "                elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
        "                    # weights of blacklist modules will NOT be weight decayed\n",
        "                    no_decay.add(fpn)\n",
        "\n",
        "        # special case the position embedding parameter in the root GPT module as not decayed\n",
        "        no_decay.add('pos_emb')\n",
        "\n",
        "        # validate that we considered every parameter\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        inter_params = decay & no_decay\n",
        "        union_params = decay | no_decay\n",
        "        assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
        "        assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
        "                                                    % (str(param_dict.keys() - union_params), )\n",
        "\n",
        "        # create the pytorch optimizer object\n",
        "        optim_groups = [\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": train_config.weight_decay},\n",
        "            {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=train_config.learning_rate, betas=train_config.betas)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.block_size, \"Cannot forward, model block size is exhausted.\"\n",
        "\n",
        "        # forward the GPT model\n",
        "        token_embeddings = self.tok_emb(idx) # each index maps to a (learnable) vector\n",
        "        position_embeddings = self.pos_emb[:, :t, :] # each position maps to a (learnable) vector\n",
        "        x = self.drop(token_embeddings + position_embeddings)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "        return logits, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:27.961284Z",
          "iopub.status.busy": "2020-10-15T08:02:27.960501Z",
          "iopub.status.idle": "2020-10-15T08:02:27.968384Z",
          "shell.execute_reply": "2020-10-15T08:02:27.967606Z"
        },
        "papermill": {
          "duration": 0.035277,
          "end_time": "2020-10-15T08:02:27.968547",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.933270",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# make deterministic\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:28.019710Z",
          "iopub.status.busy": "2020-10-15T08:02:28.018774Z",
          "iopub.status.idle": "2020-10-15T08:02:40.975252Z",
          "shell.execute_reply": "2020-10-15T08:02:40.974420Z"
        },
        "papermill": {
          "duration": 12.98631,
          "end_time": "2020-10-15T08:02:40.975395",
          "exception": false,
          "start_time": "2020-10-15T08:02:27.989085",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f9560142b614398bdfc4a2099ffbecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000 10000\n"
          ]
        }
      ],
      "source": [
        "# pytorch helpfully makes it easy to download datasets, e.g. the common CIFAR-10 https://www.kaggle.com/c/cifar-10\n",
        "root = './'\n",
        "train_data = torchvision.datasets.CIFAR10(root, train=True, transform=None, target_transform=None, download=True)\n",
        "test_data  = torchvision.datasets.CIFAR10(root, train=False, transform=None, target_transform=None, download=True)\n",
        "print(len(train_data), len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:41.320334Z",
          "iopub.status.busy": "2020-10-15T08:02:41.319418Z",
          "iopub.status.idle": "2020-10-15T08:02:49.251213Z",
          "shell.execute_reply": "2020-10-15T08:02:49.250489Z"
        },
        "papermill": {
          "duration": 8.253621,
          "end_time": "2020-10-15T08:02:49.251354",
          "exception": false,
          "start_time": "2020-10-15T08:02:40.997733",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([250000, 3])\n"
          ]
        }
      ],
      "source": [
        "# get random 5 pixels per image and stack them all up as rgb values to get half a million random pixels\n",
        "pluck_rgb = lambda x: torch.from_numpy(np.array(x)).view(32*32, 3)[torch.randperm(32*32)[:5], :]\n",
        "px = torch.cat([pluck_rgb(x) for x, y in train_data], dim=0).float()\n",
        "print(px.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:02:49.319517Z",
          "iopub.status.busy": "2020-10-15T08:02:49.313541Z",
          "iopub.status.idle": "2020-10-15T08:03:19.877300Z",
          "shell.execute_reply": "2020-10-15T08:03:19.877999Z"
        },
        "papermill": {
          "duration": 30.599131,
          "end_time": "2020-10-15T08:03:19.878175",
          "exception": false,
          "start_time": "2020-10-15T08:02:49.279044",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 1/8, re-initialized 4 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 2/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 3/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 4/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 5/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 6/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 7/8, re-initialized 0 dead clusters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done step 8/8, re-initialized 0 dead clusters\n",
            "torch.Size([512, 3])\n"
          ]
        }
      ],
      "source": [
        "# run kmeans to get our codebook\n",
        "\n",
        "def kmeans(x, ncluster, niter=10):\n",
        "    N, D = x.size()\n",
        "    c = x[torch.randperm(N)[:ncluster]] # init clusters at random\n",
        "    for i in range(niter):\n",
        "        # assign all pixels to the closest codebook element\n",
        "        a = ((x[:, None, :] - c[None, :, :])**2).sum(-1).argmin(1)\n",
        "        # move each codebook element to be the mean of the pixels that assigned to it\n",
        "        c = torch.stack([x[a==k].mean(0) for k in range(ncluster)])\n",
        "        # re-assign any poorly positioned codebook elements\n",
        "        nanix = torch.any(torch.isnan(c), dim=1)\n",
        "        ndead = nanix.sum().item()\n",
        "        print('done step %d/%d, re-initialized %d dead clusters' % (i+1, niter, ndead))\n",
        "        c[nanix] = x[torch.randperm(N)[:ndead]] # re-init dead clusters\n",
        "    return c\n",
        "\n",
        "ncluster = 512\n",
        "with torch.no_grad():\n",
        "    C = kmeans(px, ncluster, niter=8)\n",
        "\n",
        "print(C.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:03:19.946132Z",
          "iopub.status.busy": "2020-10-15T08:03:19.945192Z",
          "iopub.status.idle": "2020-10-15T08:03:20.871909Z",
          "shell.execute_reply": "2020-10-15T08:03:20.872527Z"
        },
        "papermill": {
          "duration": 0.966647,
          "end_time": "2020-10-15T08:03:20.872688",
          "exception": false,
          "start_time": "2020-10-15T08:03:19.906041",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x720 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# encode the training examples with our codebook to visualize how much we've lost in the discretization\n",
        "n_samples = 16\n",
        "ncol = 8\n",
        "nrow = n_samples // ncol + 1\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(n_samples):\n",
        "    \n",
        "    # encode and decode random data\n",
        "    x, y = train_data[np.random.randint(0, len(train_data))]\n",
        "    xpt = torch.from_numpy(np.array(x)).float().view(32*32, 3)\n",
        "    ix = ((xpt[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1) # cluster assignments for each pixel\n",
        "    \n",
        "    # these images should look normal ideally\n",
        "    plt.subplot(nrow, ncol, i+1)\n",
        "    plt.imshow(C[ix].view(32, 32, 3).numpy().astype(np.uint8))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.026512,
          "end_time": "2020-10-15T08:03:20.926206",
          "exception": false,
          "start_time": "2020-10-15T08:03:20.899694",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The images above look relatively reasonable, so our 512-sized codebook is enough to reasonably re-represent RGB values. Ok cool. So now every image is just a 1024-long sequence of numbers between 0..511. Time to train a GPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:03:20.996779Z",
          "iopub.status.busy": "2020-10-15T08:03:20.995925Z",
          "iopub.status.idle": "2020-10-15T08:03:21.018761Z",
          "shell.execute_reply": "2020-10-15T08:03:21.018069Z"
        },
        "papermill": {
          "duration": 0.065899,
          "end_time": "2020-10-15T08:03:21.018897",
          "exception": false,
          "start_time": "2020-10-15T08:03:20.952998",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([449, 229, 229,  ..., 379,   0, 177])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    wrap up the pytorch CIFAR-10 dataset into our own, which will convert images into sequences of integers\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, pt_dataset, clusters, perm=None):\n",
        "        self.pt_dataset = pt_dataset\n",
        "        self.clusters = clusters\n",
        "        self.perm = torch.arange(32*32) if perm is None else perm\n",
        "        \n",
        "        self.vocab_size = clusters.size(0)\n",
        "        self.block_size = 32*32 - 1\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.pt_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.pt_dataset[idx]\n",
        "        x = torch.from_numpy(np.array(x)).view(-1, 3) # flatten out all pixels\n",
        "        x = x[self.perm].float() # reshuffle pixels with any fixed permutation and -> float\n",
        "        a = ((x[:, None, :] - self.clusters[None, :, :])**2).sum(-1).argmin(1) # cluster assignments\n",
        "        return a[:-1], a[1:] # always just predict the next one in the sequence\n",
        "\n",
        "train_dataset = ImageDataset(train_data, C)\n",
        "test_dataset = ImageDataset(test_data, C)\n",
        "train_dataset[0][0] # one example image flattened out into integers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.027856,
          "end_time": "2020-10-15T08:03:21.074613",
          "exception": false,
          "start_time": "2020-10-15T08:03:21.046757",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "\n",
        "For reference, **iGPT-S** from the paper is:\n",
        "- batch size of 128 and trained for 1M terations\n",
        "- Adam lr 0.003 with betas = (0.9, 0.95)\n",
        "- learning rate is warmed up for one epoch, then decays to 0\n",
        "- did not use weight decay or dropout\n",
        "- `n_layer=24, n_head=8, n_embd=512`\n",
        "\n",
        "We will do something similar but smaller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:03:21.140337Z",
          "iopub.status.busy": "2020-10-15T08:03:21.139569Z",
          "iopub.status.idle": "2020-10-15T08:03:21.417047Z",
          "shell.execute_reply": "2020-10-15T08:03:21.416103Z"
        },
        "papermill": {
          "duration": 0.313681,
          "end_time": "2020-10-15T08:03:21.417226",
          "exception": false,
          "start_time": "2020-10-15T08:03:21.103545",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "# we'll do something a bit smaller\n",
        "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
        "                  embd_pdrop=0.0, resid_pdrop=0.0, attn_pdrop=0.0,\n",
        "                  n_layer=12, n_head=8, n_embd=256)\n",
        "model = GPT(mconf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-15T08:03:21.498509Z",
          "iopub.status.busy": "2020-10-15T08:03:21.497683Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": false,
          "start_time": "2020-10-15T08:03:21.447699",
          "status": "running"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "  0%|          | 0/6250 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 0: train loss 6.29280. lr 4.800000e-07:   0%|          | 0/6250 [00:29<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 0: train loss 6.29280. lr 4.800000e-07:   0%|          | 1/6250 [00:29<52:02:45, 29.98s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 1: train loss 6.31060. lr 9.600000e-07:   0%|          | 1/6250 [00:55<52:02:45, 29.98s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 1: train loss 6.31060. lr 9.600000e-07:   0%|          | 2/6250 [00:55<49:31:20, 28.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 2: train loss 6.30733. lr 1.440000e-06:   0%|          | 2/6250 [01:17<49:31:20, 28.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 2: train loss 6.30733. lr 1.440000e-06:   0%|          | 3/6250 [01:17<46:19:03, 26.69s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 3: train loss 6.25031. lr 1.920000e-06:   0%|          | 3/6250 [01:40<46:19:03, 26.69s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 3: train loss 6.25031. lr 1.920000e-06:   0%|          | 4/6250 [01:40<44:11:28, 25.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 4: train loss 6.33509. lr 2.400000e-06:   0%|          | 4/6250 [02:03<44:11:28, 25.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 4: train loss 6.33509. lr 2.400000e-06:   0%|          | 5/6250 [02:03<43:08:26, 24.87s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 5: train loss 6.31169. lr 2.880000e-06:   0%|          | 5/6250 [02:25<43:08:26, 24.87s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 5: train loss 6.31169. lr 2.880000e-06:   0%|          | 6/6250 [02:25<41:32:18, 23.95s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 6: train loss 6.19094. lr 3.360000e-06:   0%|          | 6/6250 [02:46<41:32:18, 23.95s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 6: train loss 6.19094. lr 3.360000e-06:   0%|          | 7/6250 [02:46<40:00:13, 23.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 7: train loss 6.30672. lr 3.840000e-06:   0%|          | 7/6250 [03:08<40:00:13, 23.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 7: train loss 6.30672. lr 3.840000e-06:   0%|          | 8/6250 [03:08<39:26:31, 22.75s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 8: train loss 6.27023. lr 4.320000e-06:   0%|          | 8/6250 [03:29<39:26:31, 22.75s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 8: train loss 6.27023. lr 4.320000e-06:   0%|          | 9/6250 [03:29<38:37:24, 22.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 9: train loss 6.31565. lr 4.800000e-06:   0%|          | 9/6250 [03:51<38:37:24, 22.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 9: train loss 6.31565. lr 4.800000e-06:   0%|          | 10/6250 [03:51<38:21:31, 22.13s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 10: train loss 6.27451. lr 5.280000e-06:   0%|          | 10/6250 [04:14<38:21:31, 22.13s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 10: train loss 6.27451. lr 5.280000e-06:   0%|          | 11/6250 [04:14<38:47:05, 22.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 11: train loss 6.19173. lr 5.760000e-06:   0%|          | 11/6250 [04:36<38:47:05, 22.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 11: train loss 6.19173. lr 5.760000e-06:   0%|          | 12/6250 [04:36<38:25:36, 22.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 12: train loss 6.23338. lr 6.240000e-06:   0%|          | 12/6250 [04:59<38:25:36, 22.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 12: train loss 6.23338. lr 6.240000e-06:   0%|          | 13/6250 [04:59<39:04:25, 22.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 13: train loss 6.26474. lr 6.720000e-06:   0%|          | 13/6250 [05:21<39:04:25, 22.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 13: train loss 6.26474. lr 6.720000e-06:   0%|          | 14/6250 [05:21<38:50:06, 22.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 14: train loss 6.30889. lr 7.200000e-06:   0%|          | 14/6250 [05:42<38:50:06, 22.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 14: train loss 6.30889. lr 7.200000e-06:   0%|          | 15/6250 [05:42<38:02:58, 21.97s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 15: train loss 6.28060. lr 7.680000e-06:   0%|          | 15/6250 [06:03<38:02:58, 21.97s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 15: train loss 6.28060. lr 7.680000e-06:   0%|          | 16/6250 [06:03<37:46:28, 21.81s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 16: train loss 6.24395. lr 8.160000e-06:   0%|          | 16/6250 [06:25<37:46:28, 21.81s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 16: train loss 6.24395. lr 8.160000e-06:   0%|          | 17/6250 [06:25<37:30:58, 21.67s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 17: train loss 6.22388. lr 8.640000e-06:   0%|          | 17/6250 [06:46<37:30:58, 21.67s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 17: train loss 6.22388. lr 8.640000e-06:   0%|          | 18/6250 [06:46<37:26:27, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 18: train loss 6.29463. lr 9.120000e-06:   0%|          | 18/6250 [07:08<37:26:27, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 18: train loss 6.29463. lr 9.120000e-06:   0%|          | 19/6250 [07:08<37:24:59, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 19: train loss 6.14259. lr 9.600000e-06:   0%|          | 19/6250 [07:29<37:24:59, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 19: train loss 6.14259. lr 9.600000e-06:   0%|          | 20/6250 [07:29<37:14:14, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 20: train loss 6.27257. lr 1.008000e-05:   0%|          | 20/6250 [07:50<37:14:14, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 20: train loss 6.27257. lr 1.008000e-05:   0%|          | 21/6250 [07:50<37:00:19, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 21: train loss 6.20481. lr 1.056000e-05:   0%|          | 21/6250 [08:12<37:00:19, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 21: train loss 6.20481. lr 1.056000e-05:   0%|          | 22/6250 [08:12<37:10:01, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 22: train loss 6.26640. lr 1.104000e-05:   0%|          | 22/6250 [08:33<37:10:01, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 22: train loss 6.26640. lr 1.104000e-05:   0%|          | 23/6250 [08:33<36:45:20, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 23: train loss 6.26989. lr 1.152000e-05:   0%|          | 23/6250 [08:54<36:45:20, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 23: train loss 6.26989. lr 1.152000e-05:   0%|          | 24/6250 [08:54<36:38:36, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 24: train loss 6.18657. lr 1.200000e-05:   0%|          | 24/6250 [09:16<36:38:36, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 24: train loss 6.18657. lr 1.200000e-05:   0%|          | 25/6250 [09:16<36:58:07, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 25: train loss 6.23137. lr 1.248000e-05:   0%|          | 25/6250 [09:36<36:58:07, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 25: train loss 6.23137. lr 1.248000e-05:   0%|          | 26/6250 [09:36<36:37:41, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 26: train loss 6.27650. lr 1.296000e-05:   0%|          | 26/6250 [09:57<36:37:41, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 26: train loss 6.27650. lr 1.296000e-05:   0%|          | 27/6250 [09:57<36:36:27, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 27: train loss 6.12286. lr 1.344000e-05:   0%|          | 27/6250 [10:20<36:36:27, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 27: train loss 6.12286. lr 1.344000e-05:   0%|          | 28/6250 [10:20<37:07:31, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 28: train loss 6.19112. lr 1.392000e-05:   0%|          | 28/6250 [10:41<37:07:31, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 28: train loss 6.19112. lr 1.392000e-05:   0%|          | 29/6250 [10:41<36:56:17, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 29: train loss 6.20045. lr 1.440000e-05:   0%|          | 29/6250 [11:02<36:56:17, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 29: train loss 6.20045. lr 1.440000e-05:   0%|          | 30/6250 [11:02<37:06:20, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 30: train loss 6.18595. lr 1.488000e-05:   0%|          | 30/6250 [11:24<37:06:20, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 30: train loss 6.18595. lr 1.488000e-05:   0%|          | 31/6250 [11:24<36:55:54, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 31: train loss 6.23331. lr 1.536000e-05:   0%|          | 31/6250 [11:45<36:55:54, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 31: train loss 6.23331. lr 1.536000e-05:   1%|          | 32/6250 [11:45<36:40:23, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 32: train loss 6.23513. lr 1.584000e-05:   1%|          | 32/6250 [12:06<36:40:23, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 32: train loss 6.23513. lr 1.584000e-05:   1%|          | 33/6250 [12:06<36:58:14, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 33: train loss 6.20896. lr 1.632000e-05:   1%|          | 33/6250 [12:28<36:58:14, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 33: train loss 6.20896. lr 1.632000e-05:   1%|          | 34/6250 [12:28<37:02:54, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 34: train loss 6.21309. lr 1.680000e-05:   1%|          | 34/6250 [12:49<37:02:54, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 34: train loss 6.21309. lr 1.680000e-05:   1%|          | 35/6250 [12:49<36:44:36, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 35: train loss 6.20308. lr 1.728000e-05:   1%|          | 35/6250 [13:10<36:44:36, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 35: train loss 6.20308. lr 1.728000e-05:   1%|          | 36/6250 [13:10<36:56:27, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 36: train loss 6.29224. lr 1.776000e-05:   1%|          | 36/6250 [13:32<36:56:27, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 36: train loss 6.29224. lr 1.776000e-05:   1%|          | 37/6250 [13:32<36:50:59, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 37: train loss 6.15712. lr 1.824000e-05:   1%|          | 37/6250 [13:53<36:50:59, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 37: train loss 6.15712. lr 1.824000e-05:   1%|          | 38/6250 [13:53<36:49:26, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 38: train loss 6.24766. lr 1.872000e-05:   1%|          | 38/6250 [14:15<36:49:26, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 38: train loss 6.24766. lr 1.872000e-05:   1%|          | 39/6250 [14:15<37:01:51, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 39: train loss 6.19453. lr 1.920000e-05:   1%|          | 39/6250 [14:36<37:01:51, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 39: train loss 6.19453. lr 1.920000e-05:   1%|          | 40/6250 [14:36<36:52:26, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 40: train loss 6.09186. lr 1.968000e-05:   1%|          | 40/6250 [14:57<36:52:26, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 40: train loss 6.09186. lr 1.968000e-05:   1%|          | 41/6250 [14:57<36:30:45, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 41: train loss 6.20617. lr 2.016000e-05:   1%|          | 41/6250 [15:19<36:30:45, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 41: train loss 6.20617. lr 2.016000e-05:   1%|          | 42/6250 [15:19<36:58:38, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 42: train loss 6.13151. lr 2.064000e-05:   1%|          | 42/6250 [15:40<36:58:38, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 42: train loss 6.13151. lr 2.064000e-05:   1%|          | 43/6250 [15:40<36:54:41, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 43: train loss 6.16796. lr 2.112000e-05:   1%|          | 43/6250 [16:02<36:54:41, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 43: train loss 6.16796. lr 2.112000e-05:   1%|          | 44/6250 [16:02<37:11:32, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 44: train loss 6.33122. lr 2.160000e-05:   1%|          | 44/6250 [16:24<37:11:32, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 44: train loss 6.33122. lr 2.160000e-05:   1%|          | 45/6250 [16:24<37:12:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 45: train loss 6.23562. lr 2.208000e-05:   1%|          | 45/6250 [16:45<37:12:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 45: train loss 6.23562. lr 2.208000e-05:   1%|          | 46/6250 [16:45<36:56:17, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 46: train loss 6.06347. lr 2.256000e-05:   1%|          | 46/6250 [17:08<36:56:17, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 46: train loss 6.06347. lr 2.256000e-05:   1%|          | 47/6250 [17:08<37:41:30, 21.87s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 47: train loss 6.23523. lr 2.304000e-05:   1%|          | 47/6250 [17:29<37:41:30, 21.87s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 47: train loss 6.23523. lr 2.304000e-05:   1%|          | 48/6250 [17:29<37:18:06, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 48: train loss 6.13406. lr 2.352000e-05:   1%|          | 48/6250 [17:50<37:18:06, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 48: train loss 6.13406. lr 2.352000e-05:   1%|          | 49/6250 [17:50<37:12:48, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 49: train loss 6.18942. lr 2.400000e-05:   1%|          | 49/6250 [18:12<37:12:48, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 49: train loss 6.18942. lr 2.400000e-05:   1%|          | 50/6250 [18:12<37:07:43, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 50: train loss 6.24431. lr 2.448000e-05:   1%|          | 50/6250 [18:33<37:07:43, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 50: train loss 6.24431. lr 2.448000e-05:   1%|          | 51/6250 [18:33<36:51:57, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 51: train loss 5.94540. lr 2.496000e-05:   1%|          | 51/6250 [18:54<36:51:57, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 51: train loss 5.94540. lr 2.496000e-05:   1%|          | 52/6250 [18:54<36:46:51, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 52: train loss 6.13434. lr 2.544000e-05:   1%|          | 52/6250 [19:15<36:46:51, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 52: train loss 6.13434. lr 2.544000e-05:   1%|          | 53/6250 [19:15<36:50:00, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 53: train loss 6.05104. lr 2.592000e-05:   1%|          | 53/6250 [19:36<36:50:00, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 53: train loss 6.05104. lr 2.592000e-05:   1%|          | 54/6250 [19:36<36:37:18, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 54: train loss 6.17633. lr 2.640000e-05:   1%|          | 54/6250 [19:58<36:37:18, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 54: train loss 6.17633. lr 2.640000e-05:   1%|          | 55/6250 [19:58<36:36:30, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 55: train loss 6.13064. lr 2.688000e-05:   1%|          | 55/6250 [20:19<36:36:30, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 55: train loss 6.13064. lr 2.688000e-05:   1%|          | 56/6250 [20:19<36:36:19, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 56: train loss 6.09470. lr 2.736000e-05:   1%|          | 56/6250 [20:40<36:36:19, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 56: train loss 6.09470. lr 2.736000e-05:   1%|          | 57/6250 [20:40<36:32:09, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 57: train loss 6.18662. lr 2.784000e-05:   1%|          | 57/6250 [21:02<36:32:09, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 57: train loss 6.18662. lr 2.784000e-05:   1%|          | 58/6250 [21:02<36:44:35, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 58: train loss 6.14048. lr 2.832000e-05:   1%|          | 58/6250 [21:23<36:44:35, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 58: train loss 6.14048. lr 2.832000e-05:   1%|          | 59/6250 [21:23<36:48:25, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 59: train loss 6.16428. lr 2.880000e-05:   1%|          | 59/6250 [21:45<36:48:25, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 59: train loss 6.16428. lr 2.880000e-05:   1%|          | 60/6250 [21:45<36:41:24, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 60: train loss 6.18027. lr 2.928000e-05:   1%|          | 60/6250 [22:06<36:41:24, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 60: train loss 6.18027. lr 2.928000e-05:   1%|          | 61/6250 [22:06<36:55:43, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 61: train loss 6.11975. lr 2.976000e-05:   1%|          | 61/6250 [22:27<36:55:43, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 61: train loss 6.11975. lr 2.976000e-05:   1%|          | 62/6250 [22:27<36:38:58, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 62: train loss 6.13694. lr 3.024000e-05:   1%|          | 62/6250 [22:49<36:38:58, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 62: train loss 6.13694. lr 3.024000e-05:   1%|          | 63/6250 [22:49<36:43:39, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 63: train loss 5.98684. lr 3.072000e-05:   1%|          | 63/6250 [23:11<36:43:39, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 63: train loss 5.98684. lr 3.072000e-05:   1%|          | 64/6250 [23:11<36:56:54, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 64: train loss 6.17745. lr 3.120000e-05:   1%|          | 64/6250 [23:31<36:56:54, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 64: train loss 6.17745. lr 3.120000e-05:   1%|          | 65/6250 [23:31<36:34:11, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 65: train loss 6.12363. lr 3.168000e-05:   1%|          | 65/6250 [23:53<36:34:11, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 65: train loss 6.12363. lr 3.168000e-05:   1%|          | 66/6250 [23:53<36:32:22, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 66: train loss 6.06047. lr 3.216000e-05:   1%|          | 66/6250 [24:15<36:32:22, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 66: train loss 6.06047. lr 3.216000e-05:   1%|          | 67/6250 [24:15<36:56:07, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 67: train loss 5.95987. lr 3.264000e-05:   1%|          | 67/6250 [24:35<36:56:07, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 67: train loss 5.95987. lr 3.264000e-05:   1%|          | 68/6250 [24:35<36:33:43, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 68: train loss 6.03712. lr 3.312000e-05:   1%|          | 68/6250 [24:57<36:33:43, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 68: train loss 6.03712. lr 3.312000e-05:   1%|          | 69/6250 [24:57<36:30:38, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 69: train loss 6.12989. lr 3.360000e-05:   1%|          | 69/6250 [25:18<36:30:38, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 69: train loss 6.12989. lr 3.360000e-05:   1%|          | 70/6250 [25:18<36:43:26, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 70: train loss 6.12571. lr 3.408000e-05:   1%|          | 70/6250 [25:39<36:43:26, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 70: train loss 6.12571. lr 3.408000e-05:   1%|          | 71/6250 [25:39<36:22:59, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 71: train loss 5.96498. lr 3.456000e-05:   1%|          | 71/6250 [26:01<36:22:59, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 71: train loss 5.96498. lr 3.456000e-05:   1%|          | 72/6250 [26:01<36:43:13, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 72: train loss 5.85589. lr 3.504000e-05:   1%|          | 72/6250 [26:23<36:43:13, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 72: train loss 5.85589. lr 3.504000e-05:   1%|          | 73/6250 [26:23<36:52:27, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 73: train loss 6.13946. lr 3.552000e-05:   1%|          | 73/6250 [26:44<36:52:27, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 73: train loss 6.13946. lr 3.552000e-05:   1%|          | 74/6250 [26:44<36:47:31, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 74: train loss 6.05950. lr 3.600000e-05:   1%|          | 74/6250 [27:06<36:47:31, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 74: train loss 6.05950. lr 3.600000e-05:   1%|          | 75/6250 [27:06<37:02:22, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 75: train loss 6.12531. lr 3.648000e-05:   1%|          | 75/6250 [27:27<37:02:22, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 75: train loss 6.12531. lr 3.648000e-05:   1%|          | 76/6250 [27:27<36:46:52, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 76: train loss 6.12034. lr 3.696000e-05:   1%|          | 76/6250 [27:48<36:46:52, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 76: train loss 6.12034. lr 3.696000e-05:   1%|          | 77/6250 [27:48<36:27:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 77: train loss 6.07100. lr 3.744000e-05:   1%|          | 77/6250 [28:10<36:27:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 77: train loss 6.07100. lr 3.744000e-05:   1%|          | 78/6250 [28:10<36:58:05, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 78: train loss 6.11631. lr 3.792000e-05:   1%|          | 78/6250 [28:31<36:58:05, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 78: train loss 6.11631. lr 3.792000e-05:   1%|▏         | 79/6250 [28:31<36:37:50, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 79: train loss 6.12321. lr 3.840000e-05:   1%|▏         | 79/6250 [28:53<36:37:50, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 79: train loss 6.12321. lr 3.840000e-05:   1%|▏         | 80/6250 [28:53<36:42:49, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 80: train loss 6.10412. lr 3.888000e-05:   1%|▏         | 80/6250 [29:14<36:42:49, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 80: train loss 6.10412. lr 3.888000e-05:   1%|▏         | 81/6250 [29:14<36:56:18, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 81: train loss 6.13081. lr 3.936000e-05:   1%|▏         | 81/6250 [29:35<36:56:18, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 81: train loss 6.13081. lr 3.936000e-05:   1%|▏         | 82/6250 [29:35<36:33:32, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 82: train loss 5.99502. lr 3.984000e-05:   1%|▏         | 82/6250 [29:57<36:33:32, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 82: train loss 5.99502. lr 3.984000e-05:   1%|▏         | 83/6250 [29:57<36:50:51, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 83: train loss 5.81713. lr 4.032000e-05:   1%|▏         | 83/6250 [30:19<36:50:51, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 83: train loss 5.81713. lr 4.032000e-05:   1%|▏         | 84/6250 [30:19<37:10:41, 21.71s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 84: train loss 6.11558. lr 4.080000e-05:   1%|▏         | 84/6250 [30:40<37:10:41, 21.71s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 84: train loss 6.11558. lr 4.080000e-05:   1%|▏         | 85/6250 [30:40<36:40:21, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 85: train loss 6.15724. lr 4.128000e-05:   1%|▏         | 85/6250 [31:02<36:40:21, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 85: train loss 6.15724. lr 4.128000e-05:   1%|▏         | 86/6250 [31:02<36:51:54, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 86: train loss 6.08232. lr 4.176000e-05:   1%|▏         | 86/6250 [31:24<36:51:54, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 86: train loss 6.08232. lr 4.176000e-05:   1%|▏         | 87/6250 [31:24<36:55:01, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 87: train loss 6.04171. lr 4.224000e-05:   1%|▏         | 87/6250 [31:45<36:55:01, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 87: train loss 6.04171. lr 4.224000e-05:   1%|▏         | 88/6250 [31:45<36:43:45, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 88: train loss 6.13275. lr 4.272000e-05:   1%|▏         | 88/6250 [32:09<36:43:45, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 88: train loss 6.13275. lr 4.272000e-05:   1%|▏         | 89/6250 [32:09<38:13:23, 22.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 89: train loss 5.92351. lr 4.320000e-05:   1%|▏         | 89/6250 [32:30<38:13:23, 22.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 89: train loss 5.92351. lr 4.320000e-05:   1%|▏         | 90/6250 [32:30<37:40:00, 22.01s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 90: train loss 5.91756. lr 4.368000e-05:   1%|▏         | 90/6250 [32:52<37:40:00, 22.01s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 90: train loss 5.91756. lr 4.368000e-05:   1%|▏         | 91/6250 [32:52<37:14:02, 21.76s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 91: train loss 6.07095. lr 4.416000e-05:   1%|▏         | 91/6250 [33:13<37:14:02, 21.76s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 91: train loss 6.07095. lr 4.416000e-05:   1%|▏         | 92/6250 [33:13<37:16:26, 21.79s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 92: train loss 6.04552. lr 4.464000e-05:   1%|▏         | 92/6250 [33:35<37:16:26, 21.79s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 92: train loss 6.04552. lr 4.464000e-05:   1%|▏         | 93/6250 [33:35<37:02:37, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 93: train loss 5.93960. lr 4.512000e-05:   1%|▏         | 93/6250 [33:56<37:02:37, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 93: train loss 5.93960. lr 4.512000e-05:   2%|▏         | 94/6250 [33:56<36:50:22, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 94: train loss 6.00581. lr 4.560000e-05:   2%|▏         | 94/6250 [34:18<36:50:22, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 94: train loss 6.00581. lr 4.560000e-05:   2%|▏         | 95/6250 [34:18<36:55:38, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 95: train loss 6.00509. lr 4.608000e-05:   2%|▏         | 95/6250 [34:39<36:55:38, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 95: train loss 6.00509. lr 4.608000e-05:   2%|▏         | 96/6250 [34:39<36:34:17, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 96: train loss 6.05755. lr 4.656000e-05:   2%|▏         | 96/6250 [35:00<36:34:17, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 96: train loss 6.05755. lr 4.656000e-05:   2%|▏         | 97/6250 [35:00<36:36:48, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 97: train loss 5.98353. lr 4.704000e-05:   2%|▏         | 97/6250 [35:22<36:36:48, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 97: train loss 5.98353. lr 4.704000e-05:   2%|▏         | 98/6250 [35:22<36:41:45, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 98: train loss 5.99075. lr 4.752000e-05:   2%|▏         | 98/6250 [35:43<36:41:45, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 98: train loss 5.99075. lr 4.752000e-05:   2%|▏         | 99/6250 [35:43<36:22:16, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 99: train loss 6.02323. lr 4.800000e-05:   2%|▏         | 99/6250 [36:04<36:22:16, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 99: train loss 6.02323. lr 4.800000e-05:   2%|▏         | 100/6250 [36:04<36:28:29, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 100: train loss 5.99977. lr 4.848000e-05:   2%|▏         | 100/6250 [36:25<36:28:29, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 100: train loss 5.99977. lr 4.848000e-05:   2%|▏         | 101/6250 [36:25<36:16:34, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 101: train loss 5.89094. lr 4.896000e-05:   2%|▏         | 101/6250 [36:46<36:16:34, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 101: train loss 5.89094. lr 4.896000e-05:   2%|▏         | 102/6250 [36:46<36:17:10, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 102: train loss 6.08436. lr 4.944000e-05:   2%|▏         | 102/6250 [37:08<36:17:10, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 102: train loss 6.08436. lr 4.944000e-05:   2%|▏         | 103/6250 [37:08<36:32:52, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 103: train loss 6.13117. lr 4.992000e-05:   2%|▏         | 103/6250 [37:30<36:32:52, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 103: train loss 6.13117. lr 4.992000e-05:   2%|▏         | 104/6250 [37:30<36:36:08, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 104: train loss 5.84851. lr 5.040000e-05:   2%|▏         | 104/6250 [37:51<36:36:08, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 104: train loss 5.84851. lr 5.040000e-05:   2%|▏         | 105/6250 [37:51<36:29:14, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 105: train loss 6.08630. lr 5.088000e-05:   2%|▏         | 105/6250 [38:13<36:29:14, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 105: train loss 6.08630. lr 5.088000e-05:   2%|▏         | 106/6250 [38:13<36:45:34, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 106: train loss 5.93463. lr 5.136000e-05:   2%|▏         | 106/6250 [38:34<36:45:34, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 106: train loss 5.93463. lr 5.136000e-05:   2%|▏         | 107/6250 [38:34<36:32:01, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 107: train loss 5.90629. lr 5.184000e-05:   2%|▏         | 107/6250 [38:55<36:32:01, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 107: train loss 5.90629. lr 5.184000e-05:   2%|▏         | 108/6250 [38:55<36:26:43, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 108: train loss 6.04641. lr 5.232000e-05:   2%|▏         | 108/6250 [39:17<36:26:43, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 108: train loss 6.04641. lr 5.232000e-05:   2%|▏         | 109/6250 [39:17<36:34:23, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 109: train loss 6.11483. lr 5.280000e-05:   2%|▏         | 109/6250 [39:38<36:34:23, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 109: train loss 6.11483. lr 5.280000e-05:   2%|▏         | 110/6250 [39:38<36:30:35, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 110: train loss 6.00940. lr 5.328000e-05:   2%|▏         | 110/6250 [40:00<36:30:35, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 110: train loss 6.00940. lr 5.328000e-05:   2%|▏         | 111/6250 [40:00<36:34:01, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 111: train loss 5.81382. lr 5.376000e-05:   2%|▏         | 111/6250 [40:21<36:34:01, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 111: train loss 5.81382. lr 5.376000e-05:   2%|▏         | 112/6250 [40:21<36:30:21, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 112: train loss 5.78856. lr 5.424000e-05:   2%|▏         | 112/6250 [40:42<36:30:21, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 112: train loss 5.78856. lr 5.424000e-05:   2%|▏         | 113/6250 [40:42<36:16:20, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 113: train loss 5.89809. lr 5.472000e-05:   2%|▏         | 113/6250 [41:04<36:16:20, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 113: train loss 5.89809. lr 5.472000e-05:   2%|▏         | 114/6250 [41:04<36:32:38, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 114: train loss 5.93093. lr 5.520000e-05:   2%|▏         | 114/6250 [41:25<36:32:38, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 114: train loss 5.93093. lr 5.520000e-05:   2%|▏         | 115/6250 [41:25<36:18:02, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 115: train loss 5.99861. lr 5.568000e-05:   2%|▏         | 115/6250 [41:46<36:18:02, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 115: train loss 5.99861. lr 5.568000e-05:   2%|▏         | 116/6250 [41:46<36:16:58, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 116: train loss 6.03823. lr 5.616000e-05:   2%|▏         | 116/6250 [42:08<36:16:58, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 116: train loss 6.03823. lr 5.616000e-05:   2%|▏         | 117/6250 [42:08<36:27:44, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 117: train loss 6.02326. lr 5.664000e-05:   2%|▏         | 117/6250 [42:29<36:27:44, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 117: train loss 6.02326. lr 5.664000e-05:   2%|▏         | 118/6250 [42:29<36:12:50, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 118: train loss 6.02982. lr 5.712000e-05:   2%|▏         | 118/6250 [42:50<36:12:50, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 118: train loss 6.02982. lr 5.712000e-05:   2%|▏         | 119/6250 [42:50<36:20:46, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 119: train loss 5.89795. lr 5.760000e-05:   2%|▏         | 119/6250 [43:12<36:20:46, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 119: train loss 5.89795. lr 5.760000e-05:   2%|▏         | 120/6250 [43:12<36:29:14, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 120: train loss 5.98390. lr 5.808000e-05:   2%|▏         | 120/6250 [43:33<36:29:14, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 120: train loss 5.98390. lr 5.808000e-05:   2%|▏         | 121/6250 [43:33<36:15:30, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 121: train loss 5.89780. lr 5.856000e-05:   2%|▏         | 121/6250 [43:54<36:15:30, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 121: train loss 5.89780. lr 5.856000e-05:   2%|▏         | 122/6250 [43:54<36:13:27, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 122: train loss 5.97042. lr 5.904000e-05:   2%|▏         | 122/6250 [44:16<36:13:27, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 122: train loss 5.97042. lr 5.904000e-05:   2%|▏         | 123/6250 [44:16<36:28:37, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 123: train loss 6.07877. lr 5.952000e-05:   2%|▏         | 123/6250 [44:37<36:28:37, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 123: train loss 6.07877. lr 5.952000e-05:   2%|▏         | 124/6250 [44:37<36:08:04, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 124: train loss 5.98111. lr 6.000000e-05:   2%|▏         | 124/6250 [44:58<36:08:04, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 124: train loss 5.98111. lr 6.000000e-05:   2%|▏         | 125/6250 [44:58<36:13:32, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 125: train loss 5.93770. lr 6.048000e-05:   2%|▏         | 125/6250 [45:20<36:13:32, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 125: train loss 5.93770. lr 6.048000e-05:   2%|▏         | 126/6250 [45:20<36:23:29, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 126: train loss 5.96580. lr 6.096000e-05:   2%|▏         | 126/6250 [45:40<36:23:29, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 126: train loss 5.96580. lr 6.096000e-05:   2%|▏         | 127/6250 [45:40<36:03:56, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 127: train loss 5.70673. lr 6.144000e-05:   2%|▏         | 127/6250 [46:02<36:03:56, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 127: train loss 5.70673. lr 6.144000e-05:   2%|▏         | 128/6250 [46:02<36:15:45, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 128: train loss 5.94960. lr 6.192000e-05:   2%|▏         | 128/6250 [46:24<36:15:45, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 128: train loss 5.94960. lr 6.192000e-05:   2%|▏         | 129/6250 [46:24<36:24:02, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 129: train loss 5.95841. lr 6.240000e-05:   2%|▏         | 129/6250 [46:44<36:24:02, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 129: train loss 5.95841. lr 6.240000e-05:   2%|▏         | 130/6250 [46:44<36:02:49, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 130: train loss 5.98333. lr 6.288000e-05:   2%|▏         | 130/6250 [47:06<36:02:49, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 130: train loss 5.98333. lr 6.288000e-05:   2%|▏         | 131/6250 [47:06<36:21:15, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 131: train loss 6.06970. lr 6.336000e-05:   2%|▏         | 131/6250 [47:28<36:21:15, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 131: train loss 6.06970. lr 6.336000e-05:   2%|▏         | 132/6250 [47:28<36:30:36, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 132: train loss 5.92709. lr 6.384000e-05:   2%|▏         | 132/6250 [47:50<36:30:36, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 132: train loss 5.92709. lr 6.384000e-05:   2%|▏         | 133/6250 [47:50<36:52:16, 21.70s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 133: train loss 5.95664. lr 6.432000e-05:   2%|▏         | 133/6250 [48:13<36:52:16, 21.70s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 133: train loss 5.95664. lr 6.432000e-05:   2%|▏         | 134/6250 [48:13<37:17:57, 21.96s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 134: train loss 5.96980. lr 6.480000e-05:   2%|▏         | 134/6250 [48:34<37:17:57, 21.96s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 134: train loss 5.96980. lr 6.480000e-05:   2%|▏         | 135/6250 [48:34<37:00:06, 21.78s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 135: train loss 5.37488. lr 6.528000e-05:   2%|▏         | 135/6250 [48:55<37:00:06, 21.78s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 135: train loss 5.37488. lr 6.528000e-05:   2%|▏         | 136/6250 [48:55<36:38:12, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 136: train loss 5.90600. lr 6.576000e-05:   2%|▏         | 136/6250 [49:17<36:38:12, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 136: train loss 5.90600. lr 6.576000e-05:   2%|▏         | 137/6250 [49:17<36:47:46, 21.67s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 137: train loss 5.70949. lr 6.624000e-05:   2%|▏         | 137/6250 [49:38<36:47:46, 21.67s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 137: train loss 5.70949. lr 6.624000e-05:   2%|▏         | 138/6250 [49:38<36:34:51, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 138: train loss 5.97829. lr 6.672000e-05:   2%|▏         | 138/6250 [49:59<36:34:51, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 138: train loss 5.97829. lr 6.672000e-05:   2%|▏         | 139/6250 [49:59<36:23:34, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 139: train loss 6.04714. lr 6.720000e-05:   2%|▏         | 139/6250 [50:21<36:23:34, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 139: train loss 6.04714. lr 6.720000e-05:   2%|▏         | 140/6250 [50:21<36:24:13, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 140: train loss 5.97403. lr 6.768000e-05:   2%|▏         | 140/6250 [50:42<36:24:13, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 140: train loss 5.97403. lr 6.768000e-05:   2%|▏         | 141/6250 [50:42<36:11:55, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 141: train loss 5.79565. lr 6.816000e-05:   2%|▏         | 141/6250 [51:03<36:11:55, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 141: train loss 5.79565. lr 6.816000e-05:   2%|▏         | 142/6250 [51:03<36:17:22, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 142: train loss 5.66181. lr 6.864000e-05:   2%|▏         | 142/6250 [51:25<36:17:22, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 142: train loss 5.66181. lr 6.864000e-05:   2%|▏         | 143/6250 [51:25<36:13:29, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 143: train loss 5.42026. lr 6.912000e-05:   2%|▏         | 143/6250 [51:46<36:13:29, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 143: train loss 5.42026. lr 6.912000e-05:   2%|▏         | 144/6250 [51:46<36:07:05, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 144: train loss 5.92327. lr 6.960000e-05:   2%|▏         | 144/6250 [52:08<36:07:05, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 144: train loss 5.92327. lr 6.960000e-05:   2%|▏         | 145/6250 [52:08<36:18:10, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 145: train loss 5.94104. lr 7.008000e-05:   2%|▏         | 145/6250 [52:29<36:18:10, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 145: train loss 5.94104. lr 7.008000e-05:   2%|▏         | 146/6250 [52:29<36:08:22, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 146: train loss 5.92840. lr 7.056000e-05:   2%|▏         | 146/6250 [52:50<36:08:22, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 146: train loss 5.92840. lr 7.056000e-05:   2%|▏         | 147/6250 [52:50<36:02:47, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 147: train loss 5.93262. lr 7.104000e-05:   2%|▏         | 147/6250 [53:11<36:02:47, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 147: train loss 5.93262. lr 7.104000e-05:   2%|▏         | 148/6250 [53:11<36:13:01, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 148: train loss 5.92134. lr 7.152000e-05:   2%|▏         | 148/6250 [53:32<36:13:01, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 148: train loss 5.92134. lr 7.152000e-05:   2%|▏         | 149/6250 [53:32<35:59:42, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 149: train loss 5.83450. lr 7.200000e-05:   2%|▏         | 149/6250 [53:53<35:59:42, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 149: train loss 5.83450. lr 7.200000e-05:   2%|▏         | 150/6250 [53:53<35:56:15, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 150: train loss 5.93053. lr 7.248000e-05:   2%|▏         | 150/6250 [54:15<35:56:15, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 150: train loss 5.93053. lr 7.248000e-05:   2%|▏         | 151/6250 [54:15<36:05:40, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 151: train loss 5.80197. lr 7.296000e-05:   2%|▏         | 151/6250 [54:36<36:05:40, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 151: train loss 5.80197. lr 7.296000e-05:   2%|▏         | 152/6250 [54:36<35:59:34, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 152: train loss 5.96071. lr 7.344000e-05:   2%|▏         | 152/6250 [54:57<35:59:34, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 152: train loss 5.96071. lr 7.344000e-05:   2%|▏         | 153/6250 [54:57<36:02:02, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 153: train loss 5.99200. lr 7.392000e-05:   2%|▏         | 153/6250 [55:19<36:02:02, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 153: train loss 5.99200. lr 7.392000e-05:   2%|▏         | 154/6250 [55:19<36:05:17, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 154: train loss 5.94181. lr 7.440000e-05:   2%|▏         | 154/6250 [55:40<36:05:17, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 154: train loss 5.94181. lr 7.440000e-05:   2%|▏         | 155/6250 [55:40<35:57:18, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 155: train loss 5.90996. lr 7.488000e-05:   2%|▏         | 155/6250 [56:01<35:57:18, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 155: train loss 5.90996. lr 7.488000e-05:   2%|▏         | 156/6250 [56:01<36:01:39, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 156: train loss 5.73647. lr 7.536000e-05:   2%|▏         | 156/6250 [56:22<36:01:39, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 156: train loss 5.73647. lr 7.536000e-05:   3%|▎         | 157/6250 [56:22<35:57:04, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 157: train loss 5.72989. lr 7.584000e-05:   3%|▎         | 157/6250 [56:44<35:57:04, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 157: train loss 5.72989. lr 7.584000e-05:   3%|▎         | 158/6250 [56:44<35:51:35, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 158: train loss 5.74061. lr 7.632000e-05:   3%|▎         | 158/6250 [57:05<35:51:35, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 158: train loss 5.74061. lr 7.632000e-05:   3%|▎         | 159/6250 [57:05<36:07:33, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 159: train loss 5.94462. lr 7.680000e-05:   3%|▎         | 159/6250 [57:26<36:07:33, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 159: train loss 5.94462. lr 7.680000e-05:   3%|▎         | 160/6250 [57:26<35:52:37, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 160: train loss 5.78312. lr 7.728000e-05:   3%|▎         | 160/6250 [57:47<35:52:37, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 160: train loss 5.78312. lr 7.728000e-05:   3%|▎         | 161/6250 [57:47<35:47:15, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 161: train loss 5.72471. lr 7.776000e-05:   3%|▎         | 161/6250 [58:09<35:47:15, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 161: train loss 5.72471. lr 7.776000e-05:   3%|▎         | 162/6250 [58:09<36:02:38, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 162: train loss 5.89827. lr 7.824000e-05:   3%|▎         | 162/6250 [58:30<36:02:38, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 162: train loss 5.89827. lr 7.824000e-05:   3%|▎         | 163/6250 [58:30<36:03:07, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 163: train loss 5.87597. lr 7.872000e-05:   3%|▎         | 163/6250 [58:52<36:03:07, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 163: train loss 5.87597. lr 7.872000e-05:   3%|▎         | 164/6250 [58:52<36:04:33, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 164: train loss 5.94685. lr 7.920000e-05:   3%|▎         | 164/6250 [59:13<36:04:33, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 164: train loss 5.94685. lr 7.920000e-05:   3%|▎         | 165/6250 [59:13<36:13:55, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 165: train loss 5.78813. lr 7.968000e-05:   3%|▎         | 165/6250 [59:34<36:13:55, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 165: train loss 5.78813. lr 7.968000e-05:   3%|▎         | 166/6250 [59:34<35:59:13, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 166: train loss 5.67571. lr 8.016000e-05:   3%|▎         | 166/6250 [59:55<35:59:13, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 166: train loss 5.67571. lr 8.016000e-05:   3%|▎         | 167/6250 [59:55<35:48:41, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 167: train loss 5.91040. lr 8.064000e-05:   3%|▎         | 167/6250 [1:00:17<35:48:41, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 167: train loss 5.91040. lr 8.064000e-05:   3%|▎         | 168/6250 [1:00:17<36:05:50, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 168: train loss 5.63121. lr 8.112000e-05:   3%|▎         | 168/6250 [1:00:38<36:05:50, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 168: train loss 5.63121. lr 8.112000e-05:   3%|▎         | 169/6250 [1:00:38<35:43:07, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 169: train loss 5.59936. lr 8.160000e-05:   3%|▎         | 169/6250 [1:00:59<35:43:07, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 169: train loss 5.59936. lr 8.160000e-05:   3%|▎         | 170/6250 [1:00:59<35:44:42, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 170: train loss 5.44404. lr 8.208000e-05:   3%|▎         | 170/6250 [1:01:20<35:44:42, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 170: train loss 5.44404. lr 8.208000e-05:   3%|▎         | 171/6250 [1:01:20<35:53:25, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 171: train loss 5.69501. lr 8.256000e-05:   3%|▎         | 171/6250 [1:01:41<35:53:25, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 171: train loss 5.69501. lr 8.256000e-05:   3%|▎         | 172/6250 [1:01:41<35:38:01, 21.11s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 172: train loss 5.38518. lr 8.304000e-05:   3%|▎         | 172/6250 [1:02:02<35:38:01, 21.11s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 172: train loss 5.38518. lr 8.304000e-05:   3%|▎         | 173/6250 [1:02:02<35:49:18, 21.22s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 173: train loss 5.74989. lr 8.352000e-05:   3%|▎         | 173/6250 [1:02:24<35:49:18, 21.22s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 173: train loss 5.74989. lr 8.352000e-05:   3%|▎         | 174/6250 [1:02:24<35:50:39, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 174: train loss 5.72783. lr 8.400000e-05:   3%|▎         | 174/6250 [1:02:45<35:50:39, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 174: train loss 5.72783. lr 8.400000e-05:   3%|▎         | 175/6250 [1:02:45<35:49:21, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 175: train loss 5.77122. lr 8.448000e-05:   3%|▎         | 175/6250 [1:03:10<35:49:21, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 175: train loss 5.77122. lr 8.448000e-05:   3%|▎         | 176/6250 [1:03:10<37:52:01, 22.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 176: train loss 5.48469. lr 8.496000e-05:   3%|▎         | 176/6250 [1:03:32<37:52:01, 22.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 176: train loss 5.48469. lr 8.496000e-05:   3%|▎         | 177/6250 [1:03:32<37:23:34, 22.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 177: train loss 5.72931. lr 8.544000e-05:   3%|▎         | 177/6250 [1:03:54<37:23:34, 22.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 177: train loss 5.72931. lr 8.544000e-05:   3%|▎         | 178/6250 [1:03:54<37:14:12, 22.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 178: train loss 5.75683. lr 8.592000e-05:   3%|▎         | 178/6250 [1:04:16<37:14:12, 22.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 178: train loss 5.75683. lr 8.592000e-05:   3%|▎         | 179/6250 [1:04:16<37:08:45, 22.03s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 179: train loss 5.85431. lr 8.640000e-05:   3%|▎         | 179/6250 [1:04:37<37:08:45, 22.03s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 179: train loss 5.85431. lr 8.640000e-05:   3%|▎         | 180/6250 [1:04:37<36:38:36, 21.73s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 180: train loss 5.81868. lr 8.688000e-05:   3%|▎         | 180/6250 [1:04:58<36:38:36, 21.73s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 180: train loss 5.81868. lr 8.688000e-05:   3%|▎         | 181/6250 [1:04:58<36:20:24, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 181: train loss 5.53726. lr 8.736000e-05:   3%|▎         | 181/6250 [1:05:19<36:20:24, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 181: train loss 5.53726. lr 8.736000e-05:   3%|▎         | 182/6250 [1:05:19<36:21:48, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 182: train loss 5.70120. lr 8.784000e-05:   3%|▎         | 182/6250 [1:05:40<36:21:48, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 182: train loss 5.70120. lr 8.784000e-05:   3%|▎         | 183/6250 [1:05:40<36:07:49, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 183: train loss 5.50479. lr 8.832000e-05:   3%|▎         | 183/6250 [1:06:02<36:07:49, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 183: train loss 5.50479. lr 8.832000e-05:   3%|▎         | 184/6250 [1:06:02<35:56:10, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 184: train loss 5.68819. lr 8.880000e-05:   3%|▎         | 184/6250 [1:06:23<35:56:10, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 184: train loss 5.68819. lr 8.880000e-05:   3%|▎         | 185/6250 [1:06:23<35:50:35, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 185: train loss 5.50201. lr 8.928000e-05:   3%|▎         | 185/6250 [1:06:44<35:50:35, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 185: train loss 5.50201. lr 8.928000e-05:   3%|▎         | 186/6250 [1:06:44<35:41:36, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 186: train loss 5.85012. lr 8.976000e-05:   3%|▎         | 186/6250 [1:07:05<35:41:36, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 186: train loss 5.85012. lr 8.976000e-05:   3%|▎         | 187/6250 [1:07:05<35:48:48, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 187: train loss 5.45349. lr 9.024000e-05:   3%|▎         | 187/6250 [1:07:26<35:48:48, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 187: train loss 5.45349. lr 9.024000e-05:   3%|▎         | 188/6250 [1:07:26<35:41:39, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 188: train loss 5.71149. lr 9.072000e-05:   3%|▎         | 188/6250 [1:07:47<35:41:39, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 188: train loss 5.71149. lr 9.072000e-05:   3%|▎         | 189/6250 [1:07:47<35:36:45, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 189: train loss 5.70449. lr 9.120000e-05:   3%|▎         | 189/6250 [1:08:09<35:36:45, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 189: train loss 5.70449. lr 9.120000e-05:   3%|▎         | 190/6250 [1:08:09<35:47:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 190: train loss 5.68861. lr 9.168000e-05:   3%|▎         | 190/6250 [1:08:30<35:47:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 190: train loss 5.68861. lr 9.168000e-05:   3%|▎         | 191/6250 [1:08:30<35:37:39, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 191: train loss 5.70576. lr 9.216000e-05:   3%|▎         | 191/6250 [1:08:51<35:37:39, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 191: train loss 5.70576. lr 9.216000e-05:   3%|▎         | 192/6250 [1:08:51<35:32:34, 21.12s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 192: train loss 5.73473. lr 9.264000e-05:   3%|▎         | 192/6250 [1:09:13<35:32:34, 21.12s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 192: train loss 5.73473. lr 9.264000e-05:   3%|▎         | 193/6250 [1:09:13<35:59:53, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 193: train loss 5.51797. lr 9.312000e-05:   3%|▎         | 193/6250 [1:09:34<35:59:53, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 193: train loss 5.51797. lr 9.312000e-05:   3%|▎         | 194/6250 [1:09:34<35:59:23, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 194: train loss 5.61539. lr 9.360000e-05:   3%|▎         | 194/6250 [1:09:55<35:59:23, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 194: train loss 5.61539. lr 9.360000e-05:   3%|▎         | 195/6250 [1:09:55<35:49:34, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 195: train loss 5.73310. lr 9.408000e-05:   3%|▎         | 195/6250 [1:10:17<35:49:34, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 195: train loss 5.73310. lr 9.408000e-05:   3%|▎         | 196/6250 [1:10:17<35:55:28, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 196: train loss 5.59077. lr 9.456000e-05:   3%|▎         | 196/6250 [1:10:38<35:55:28, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 196: train loss 5.59077. lr 9.456000e-05:   3%|▎         | 197/6250 [1:10:38<35:45:16, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 197: train loss 5.57934. lr 9.504000e-05:   3%|▎         | 197/6250 [1:10:59<35:45:16, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 197: train loss 5.57934. lr 9.504000e-05:   3%|▎         | 198/6250 [1:10:59<35:54:49, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 198: train loss 5.73970. lr 9.552000e-05:   3%|▎         | 198/6250 [1:11:21<35:54:49, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 198: train loss 5.73970. lr 9.552000e-05:   3%|▎         | 199/6250 [1:11:21<35:52:08, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 199: train loss 5.77545. lr 9.600000e-05:   3%|▎         | 199/6250 [1:11:42<35:52:08, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 199: train loss 5.77545. lr 9.600000e-05:   3%|▎         | 200/6250 [1:11:42<35:46:39, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 200: train loss 5.63599. lr 9.648000e-05:   3%|▎         | 200/6250 [1:12:04<35:46:39, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 200: train loss 5.63599. lr 9.648000e-05:   3%|▎         | 201/6250 [1:12:04<35:58:42, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 201: train loss 5.70546. lr 9.696000e-05:   3%|▎         | 201/6250 [1:12:24<35:58:42, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 201: train loss 5.70546. lr 9.696000e-05:   3%|▎         | 202/6250 [1:12:24<35:40:38, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 202: train loss 5.58331. lr 9.744000e-05:   3%|▎         | 202/6250 [1:12:45<35:40:38, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 202: train loss 5.58331. lr 9.744000e-05:   3%|▎         | 203/6250 [1:12:45<35:26:50, 21.10s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 203: train loss 5.63787. lr 9.792000e-05:   3%|▎         | 203/6250 [1:13:07<35:26:50, 21.10s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 203: train loss 5.63787. lr 9.792000e-05:   3%|▎         | 204/6250 [1:13:07<35:45:02, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 204: train loss 5.30312. lr 9.840000e-05:   3%|▎         | 204/6250 [1:13:28<35:45:02, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 204: train loss 5.30312. lr 9.840000e-05:   3%|▎         | 205/6250 [1:13:28<35:30:45, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 205: train loss 5.51475. lr 9.888000e-05:   3%|▎         | 205/6250 [1:13:49<35:30:45, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 205: train loss 5.51475. lr 9.888000e-05:   3%|▎         | 206/6250 [1:13:49<35:25:16, 21.10s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 206: train loss 5.54959. lr 9.936000e-05:   3%|▎         | 206/6250 [1:14:10<35:25:16, 21.10s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 206: train loss 5.54959. lr 9.936000e-05:   3%|▎         | 207/6250 [1:14:10<35:43:30, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 207: train loss 5.56194. lr 9.984000e-05:   3%|▎         | 207/6250 [1:14:31<35:43:30, 21.28s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 207: train loss 5.56194. lr 9.984000e-05:   3%|▎         | 208/6250 [1:14:31<35:32:10, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 208: train loss 5.66069. lr 1.003200e-04:   3%|▎         | 208/6250 [1:14:52<35:32:10, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 208: train loss 5.66069. lr 1.003200e-04:   3%|▎         | 209/6250 [1:14:52<35:31:00, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 209: train loss 5.56436. lr 1.008000e-04:   3%|▎         | 209/6250 [1:15:14<35:31:00, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 209: train loss 5.56436. lr 1.008000e-04:   3%|▎         | 210/6250 [1:15:14<35:48:54, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 210: train loss 5.61284. lr 1.012800e-04:   3%|▎         | 210/6250 [1:15:35<35:48:54, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 210: train loss 5.61284. lr 1.012800e-04:   3%|▎         | 211/6250 [1:15:35<35:30:36, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 211: train loss 5.61916. lr 1.017600e-04:   3%|▎         | 211/6250 [1:15:56<35:30:36, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 211: train loss 5.61916. lr 1.017600e-04:   3%|▎         | 212/6250 [1:15:56<35:27:28, 21.14s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 212: train loss 5.47971. lr 1.022400e-04:   3%|▎         | 212/6250 [1:16:18<35:27:28, 21.14s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 212: train loss 5.47971. lr 1.022400e-04:   3%|▎         | 213/6250 [1:16:18<35:42:28, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 213: train loss 5.59537. lr 1.027200e-04:   3%|▎         | 213/6250 [1:16:39<35:42:28, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 213: train loss 5.59537. lr 1.027200e-04:   3%|▎         | 214/6250 [1:16:39<35:28:38, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 214: train loss 5.61672. lr 1.032000e-04:   3%|▎         | 214/6250 [1:17:00<35:28:38, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 214: train loss 5.61672. lr 1.032000e-04:   3%|▎         | 215/6250 [1:17:00<35:36:26, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 215: train loss 5.46961. lr 1.036800e-04:   3%|▎         | 215/6250 [1:17:21<35:36:26, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 215: train loss 5.46961. lr 1.036800e-04:   3%|▎         | 216/6250 [1:17:21<35:36:04, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 216: train loss 5.56355. lr 1.041600e-04:   3%|▎         | 216/6250 [1:17:42<35:36:04, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 216: train loss 5.56355. lr 1.041600e-04:   3%|▎         | 217/6250 [1:17:42<35:18:31, 21.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 217: train loss 5.45625. lr 1.046400e-04:   3%|▎         | 217/6250 [1:18:03<35:18:31, 21.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 217: train loss 5.45625. lr 1.046400e-04:   3%|▎         | 218/6250 [1:18:03<35:32:33, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 218: train loss 5.41312. lr 1.051200e-04:   3%|▎         | 218/6250 [1:18:25<35:32:33, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 218: train loss 5.41312. lr 1.051200e-04:   4%|▎         | 219/6250 [1:18:25<35:42:26, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 219: train loss 5.40053. lr 1.056000e-04:   4%|▎         | 219/6250 [1:18:46<35:42:26, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 219: train loss 5.40053. lr 1.056000e-04:   4%|▎         | 220/6250 [1:18:46<35:26:59, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 220: train loss 5.51446. lr 1.060800e-04:   4%|▎         | 220/6250 [1:19:07<35:26:59, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 220: train loss 5.51446. lr 1.060800e-04:   4%|▎         | 221/6250 [1:19:07<35:42:44, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 221: train loss 5.53725. lr 1.065600e-04:   4%|▎         | 221/6250 [1:19:29<35:42:44, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 221: train loss 5.53725. lr 1.065600e-04:   4%|▎         | 222/6250 [1:19:29<35:41:47, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 222: train loss 5.45050. lr 1.070400e-04:   4%|▎         | 222/6250 [1:19:50<35:41:47, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 222: train loss 5.45050. lr 1.070400e-04:   4%|▎         | 223/6250 [1:19:50<35:28:56, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 223: train loss 5.46652. lr 1.075200e-04:   4%|▎         | 223/6250 [1:20:12<35:28:56, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 223: train loss 5.46652. lr 1.075200e-04:   4%|▎         | 224/6250 [1:20:12<35:49:22, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 224: train loss 5.35416. lr 1.080000e-04:   4%|▎         | 224/6250 [1:20:32<35:49:22, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 224: train loss 5.35416. lr 1.080000e-04:   4%|▎         | 225/6250 [1:20:32<35:28:29, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 225: train loss 5.55902. lr 1.084800e-04:   4%|▎         | 225/6250 [1:20:53<35:28:29, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 225: train loss 5.55902. lr 1.084800e-04:   4%|▎         | 226/6250 [1:20:53<35:20:38, 21.12s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 226: train loss 5.36999. lr 1.089600e-04:   4%|▎         | 226/6250 [1:21:15<35:20:38, 21.12s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 226: train loss 5.36999. lr 1.089600e-04:   4%|▎         | 227/6250 [1:21:15<35:35:03, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 227: train loss 5.41970. lr 1.094400e-04:   4%|▎         | 227/6250 [1:21:36<35:35:03, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 227: train loss 5.41970. lr 1.094400e-04:   4%|▎         | 228/6250 [1:21:36<35:19:07, 21.11s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 228: train loss 5.35209. lr 1.099200e-04:   4%|▎         | 228/6250 [1:21:57<35:19:07, 21.11s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 228: train loss 5.35209. lr 1.099200e-04:   4%|▎         | 229/6250 [1:21:57<35:14:40, 21.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 229: train loss 5.27223. lr 1.104000e-04:   4%|▎         | 229/6250 [1:22:18<35:14:40, 21.07s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 229: train loss 5.27223. lr 1.104000e-04:   4%|▎         | 230/6250 [1:22:18<35:30:13, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 230: train loss 5.36207. lr 1.108800e-04:   4%|▎         | 230/6250 [1:22:39<35:30:13, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 230: train loss 5.36207. lr 1.108800e-04:   4%|▎         | 231/6250 [1:22:39<35:14:55, 21.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 231: train loss 5.13295. lr 1.113600e-04:   4%|▎         | 231/6250 [1:23:00<35:14:55, 21.08s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 231: train loss 5.13295. lr 1.113600e-04:   4%|▎         | 232/6250 [1:23:00<35:21:05, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 232: train loss 5.37754. lr 1.118400e-04:   4%|▎         | 232/6250 [1:23:22<35:21:05, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 232: train loss 5.37754. lr 1.118400e-04:   4%|▎         | 233/6250 [1:23:22<35:30:25, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 233: train loss 5.42249. lr 1.123200e-04:   4%|▎         | 233/6250 [1:23:43<35:30:25, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 233: train loss 5.42249. lr 1.123200e-04:   4%|▎         | 234/6250 [1:23:43<35:23:00, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 234: train loss 5.37306. lr 1.128000e-04:   4%|▎         | 234/6250 [1:24:05<35:23:00, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 234: train loss 5.37306. lr 1.128000e-04:   4%|▍         | 235/6250 [1:24:05<35:44:27, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 235: train loss 4.96982. lr 1.132800e-04:   4%|▍         | 235/6250 [1:24:26<35:44:27, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 235: train loss 4.96982. lr 1.132800e-04:   4%|▍         | 236/6250 [1:24:26<35:42:41, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 236: train loss 5.26909. lr 1.137600e-04:   4%|▍         | 236/6250 [1:24:47<35:42:41, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 236: train loss 5.26909. lr 1.137600e-04:   4%|▍         | 237/6250 [1:24:47<35:23:39, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 237: train loss 5.33748. lr 1.142400e-04:   4%|▍         | 237/6250 [1:25:09<35:23:39, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 237: train loss 5.33748. lr 1.142400e-04:   4%|▍         | 238/6250 [1:25:09<35:55:53, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 238: train loss 5.39300. lr 1.147200e-04:   4%|▍         | 238/6250 [1:25:30<35:55:53, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 238: train loss 5.39300. lr 1.147200e-04:   4%|▍         | 239/6250 [1:25:30<35:40:18, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 239: train loss 5.38428. lr 1.152000e-04:   4%|▍         | 239/6250 [1:25:51<35:40:18, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 239: train loss 5.38428. lr 1.152000e-04:   4%|▍         | 240/6250 [1:25:51<35:21:15, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 240: train loss 5.36840. lr 1.156800e-04:   4%|▍         | 240/6250 [1:26:13<35:21:15, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 240: train loss 5.36840. lr 1.156800e-04:   4%|▍         | 241/6250 [1:26:13<35:43:40, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 241: train loss 5.14320. lr 1.161600e-04:   4%|▍         | 241/6250 [1:26:34<35:43:40, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 241: train loss 5.14320. lr 1.161600e-04:   4%|▍         | 242/6250 [1:26:34<35:34:49, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 242: train loss 5.27212. lr 1.166400e-04:   4%|▍         | 242/6250 [1:26:55<35:34:49, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 242: train loss 5.27212. lr 1.166400e-04:   4%|▍         | 243/6250 [1:26:55<35:17:58, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 243: train loss 5.50717. lr 1.171200e-04:   4%|▍         | 243/6250 [1:27:16<35:17:58, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 243: train loss 5.50717. lr 1.171200e-04:   4%|▍         | 244/6250 [1:27:16<35:38:49, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 244: train loss 5.46651. lr 1.176000e-04:   4%|▍         | 244/6250 [1:27:37<35:38:49, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 244: train loss 5.46651. lr 1.176000e-04:   4%|▍         | 245/6250 [1:27:37<35:26:00, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 245: train loss 5.41116. lr 1.180800e-04:   4%|▍         | 245/6250 [1:27:58<35:26:00, 21.24s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 245: train loss 5.41116. lr 1.180800e-04:   4%|▍         | 246/6250 [1:27:58<35:18:01, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 246: train loss 5.37670. lr 1.185600e-04:   4%|▍         | 246/6250 [1:28:20<35:18:01, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 246: train loss 5.37670. lr 1.185600e-04:   4%|▍         | 247/6250 [1:28:20<35:26:19, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 247: train loss 5.27046. lr 1.190400e-04:   4%|▍         | 247/6250 [1:28:41<35:26:19, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 247: train loss 5.27046. lr 1.190400e-04:   4%|▍         | 248/6250 [1:28:41<35:19:46, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 248: train loss 5.24922. lr 1.195200e-04:   4%|▍         | 248/6250 [1:29:02<35:19:46, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 248: train loss 5.24922. lr 1.195200e-04:   4%|▍         | 249/6250 [1:29:02<35:21:38, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 249: train loss 5.26290. lr 1.200000e-04:   4%|▍         | 249/6250 [1:29:23<35:21:38, 21.21s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 249: train loss 5.26290. lr 1.200000e-04:   4%|▍         | 250/6250 [1:29:23<35:19:35, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 250: train loss 5.26690. lr 1.204800e-04:   4%|▍         | 250/6250 [1:29:44<35:19:35, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 250: train loss 5.26690. lr 1.204800e-04:   4%|▍         | 251/6250 [1:29:44<35:14:50, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 251: train loss 5.34820. lr 1.209600e-04:   4%|▍         | 251/6250 [1:30:06<35:14:50, 21.15s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 251: train loss 5.34820. lr 1.209600e-04:   4%|▍         | 252/6250 [1:30:06<35:22:23, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 252: train loss 5.18032. lr 1.214400e-04:   4%|▍         | 252/6250 [1:30:27<35:22:23, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 252: train loss 5.18032. lr 1.214400e-04:   4%|▍         | 253/6250 [1:30:27<35:22:09, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 253: train loss 5.38862. lr 1.219200e-04:   4%|▍         | 253/6250 [1:30:48<35:22:09, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 253: train loss 5.38862. lr 1.219200e-04:   4%|▍         | 254/6250 [1:30:48<35:22:04, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 254: train loss 5.28191. lr 1.224000e-04:   4%|▍         | 254/6250 [1:31:10<35:22:04, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 254: train loss 5.28191. lr 1.224000e-04:   4%|▍         | 255/6250 [1:31:10<35:28:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 255: train loss 5.03350. lr 1.228800e-04:   4%|▍         | 255/6250 [1:31:31<35:28:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 255: train loss 5.03350. lr 1.228800e-04:   4%|▍         | 256/6250 [1:31:31<35:24:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 256: train loss 5.40365. lr 1.233600e-04:   4%|▍         | 256/6250 [1:31:52<35:24:50, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 256: train loss 5.40365. lr 1.233600e-04:   4%|▍         | 257/6250 [1:31:52<35:15:37, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 257: train loss 5.35594. lr 1.238400e-04:   4%|▍         | 257/6250 [1:32:13<35:15:37, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 257: train loss 5.35594. lr 1.238400e-04:   4%|▍         | 258/6250 [1:32:13<35:29:19, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 258: train loss 5.25290. lr 1.243200e-04:   4%|▍         | 258/6250 [1:32:34<35:29:19, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 258: train loss 5.25290. lr 1.243200e-04:   4%|▍         | 259/6250 [1:32:35<35:19:46, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 259: train loss 5.15961. lr 1.248000e-04:   4%|▍         | 259/6250 [1:32:56<35:19:46, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 259: train loss 5.15961. lr 1.248000e-04:   4%|▍         | 260/6250 [1:32:56<35:15:30, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 260: train loss 5.29042. lr 1.252800e-04:   4%|▍         | 260/6250 [1:33:17<35:15:30, 21.19s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 260: train loss 5.29042. lr 1.252800e-04:   4%|▍         | 261/6250 [1:33:17<35:28:26, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 261: train loss 5.17316. lr 1.257600e-04:   4%|▍         | 261/6250 [1:33:39<35:28:26, 21.32s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 261: train loss 5.17316. lr 1.257600e-04:   4%|▍         | 262/6250 [1:33:39<35:31:58, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 262: train loss 5.17972. lr 1.262400e-04:   4%|▍         | 262/6250 [1:34:00<35:31:58, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 262: train loss 5.17972. lr 1.262400e-04:   4%|▍         | 263/6250 [1:34:00<35:34:02, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 263: train loss 5.12773. lr 1.267200e-04:   4%|▍         | 263/6250 [1:34:22<35:34:02, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 263: train loss 5.12773. lr 1.267200e-04:   4%|▍         | 264/6250 [1:34:22<35:33:40, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 264: train loss 5.14015. lr 1.272000e-04:   4%|▍         | 264/6250 [1:34:43<35:33:40, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 264: train loss 5.14015. lr 1.272000e-04:   4%|▍         | 265/6250 [1:34:43<35:25:09, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 265: train loss 5.17856. lr 1.276800e-04:   4%|▍         | 265/6250 [1:35:04<35:25:09, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 265: train loss 5.17856. lr 1.276800e-04:   4%|▍         | 266/6250 [1:35:04<35:37:59, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 266: train loss 4.92563. lr 1.281600e-04:   4%|▍         | 266/6250 [1:35:26<35:37:59, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 266: train loss 4.92563. lr 1.281600e-04:   4%|▍         | 267/6250 [1:35:26<35:28:25, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 267: train loss 5.06838. lr 1.286400e-04:   4%|▍         | 267/6250 [1:35:47<35:28:25, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 267: train loss 5.06838. lr 1.286400e-04:   4%|▍         | 268/6250 [1:35:47<35:24:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 268: train loss 5.01555. lr 1.291200e-04:   4%|▍         | 268/6250 [1:36:08<35:24:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 268: train loss 5.01555. lr 1.291200e-04:   4%|▍         | 269/6250 [1:36:08<35:36:25, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 269: train loss 5.06556. lr 1.296000e-04:   4%|▍         | 269/6250 [1:36:29<35:36:25, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 269: train loss 5.06556. lr 1.296000e-04:   4%|▍         | 270/6250 [1:36:29<35:18:38, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 270: train loss 5.15220. lr 1.300800e-04:   4%|▍         | 270/6250 [1:36:50<35:18:38, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 270: train loss 5.15220. lr 1.300800e-04:   4%|▍         | 271/6250 [1:36:50<35:09:15, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 271: train loss 5.13660. lr 1.305600e-04:   4%|▍         | 271/6250 [1:37:12<35:09:15, 21.17s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 271: train loss 5.13660. lr 1.305600e-04:   4%|▍         | 272/6250 [1:37:12<35:25:52, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 272: train loss 5.17595. lr 1.310400e-04:   4%|▍         | 272/6250 [1:37:33<35:25:52, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 272: train loss 5.17595. lr 1.310400e-04:   4%|▍         | 273/6250 [1:37:33<35:07:42, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 273: train loss 5.05513. lr 1.315200e-04:   4%|▍         | 273/6250 [1:37:54<35:07:42, 21.16s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 273: train loss 5.05513. lr 1.315200e-04:   4%|▍         | 274/6250 [1:37:54<35:05:08, 21.14s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 274: train loss 5.11339. lr 1.320000e-04:   4%|▍         | 274/6250 [1:38:16<35:05:08, 21.14s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 274: train loss 5.11339. lr 1.320000e-04:   4%|▍         | 275/6250 [1:38:16<35:21:58, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 275: train loss 5.04557. lr 1.324800e-04:   4%|▍         | 275/6250 [1:38:36<35:21:58, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 275: train loss 5.04557. lr 1.324800e-04:   4%|▍         | 276/6250 [1:38:36<35:08:31, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 276: train loss 5.11688. lr 1.329600e-04:   4%|▍         | 276/6250 [1:38:58<35:08:31, 21.18s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 276: train loss 5.11688. lr 1.329600e-04:   4%|▍         | 277/6250 [1:38:58<35:13:46, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 277: train loss 5.06678. lr 1.334400e-04:   4%|▍         | 277/6250 [1:39:19<35:13:46, 21.23s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 277: train loss 5.06678. lr 1.334400e-04:   4%|▍         | 278/6250 [1:39:19<35:26:41, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 278: train loss 5.18997. lr 1.339200e-04:   4%|▍         | 278/6250 [1:39:40<35:26:41, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 278: train loss 5.18997. lr 1.339200e-04:   4%|▍         | 279/6250 [1:39:40<35:09:16, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 279: train loss 4.86851. lr 1.344000e-04:   4%|▍         | 279/6250 [1:40:02<35:09:16, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 279: train loss 4.86851. lr 1.344000e-04:   4%|▍         | 280/6250 [1:40:02<35:36:04, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 280: train loss 5.03855. lr 1.348800e-04:   4%|▍         | 280/6250 [1:40:24<35:36:04, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 280: train loss 5.03855. lr 1.348800e-04:   4%|▍         | 281/6250 [1:40:24<35:37:44, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 281: train loss 4.62551. lr 1.353600e-04:   4%|▍         | 281/6250 [1:40:45<35:37:44, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 281: train loss 4.62551. lr 1.353600e-04:   5%|▍         | 282/6250 [1:40:45<35:22:37, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 282: train loss 5.05172. lr 1.358400e-04:   5%|▍         | 282/6250 [1:41:07<35:22:37, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 282: train loss 5.05172. lr 1.358400e-04:   5%|▍         | 283/6250 [1:41:07<35:44:52, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 283: train loss 5.12628. lr 1.363200e-04:   5%|▍         | 283/6250 [1:41:28<35:44:52, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 283: train loss 5.12628. lr 1.363200e-04:   5%|▍         | 284/6250 [1:41:28<35:33:08, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 284: train loss 4.97761. lr 1.368000e-04:   5%|▍         | 284/6250 [1:41:49<35:33:08, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 284: train loss 4.97761. lr 1.368000e-04:   5%|▍         | 285/6250 [1:41:49<35:14:56, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 285: train loss 5.02574. lr 1.372800e-04:   5%|▍         | 285/6250 [1:42:11<35:14:56, 21.27s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 285: train loss 5.02574. lr 1.372800e-04:   5%|▍         | 286/6250 [1:42:11<35:35:19, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 286: train loss 4.91025. lr 1.377600e-04:   5%|▍         | 286/6250 [1:42:32<35:35:19, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 286: train loss 4.91025. lr 1.377600e-04:   5%|▍         | 287/6250 [1:42:32<35:26:26, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 287: train loss 5.01247. lr 1.382400e-04:   5%|▍         | 287/6250 [1:42:53<35:26:26, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 287: train loss 5.01247. lr 1.382400e-04:   5%|▍         | 288/6250 [1:42:53<35:15:05, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 288: train loss 5.12715. lr 1.387200e-04:   5%|▍         | 288/6250 [1:43:15<35:15:05, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 288: train loss 5.12715. lr 1.387200e-04:   5%|▍         | 289/6250 [1:43:15<35:29:01, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 289: train loss 4.70895. lr 1.392000e-04:   5%|▍         | 289/6250 [1:43:36<35:29:01, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 289: train loss 4.70895. lr 1.392000e-04:   5%|▍         | 290/6250 [1:43:36<35:21:17, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 290: train loss 5.04422. lr 1.396800e-04:   5%|▍         | 290/6250 [1:43:57<35:21:17, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 290: train loss 5.04422. lr 1.396800e-04:   5%|▍         | 291/6250 [1:43:57<35:05:57, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 291: train loss 5.01948. lr 1.401600e-04:   5%|▍         | 291/6250 [1:44:19<35:05:57, 21.20s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 291: train loss 5.01948. lr 1.401600e-04:   5%|▍         | 292/6250 [1:44:19<35:25:26, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 292: train loss 4.76945. lr 1.406400e-04:   5%|▍         | 292/6250 [1:44:40<35:25:26, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 292: train loss 4.76945. lr 1.406400e-04:   5%|▍         | 293/6250 [1:44:40<35:15:20, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 293: train loss 4.86327. lr 1.411200e-04:   5%|▍         | 293/6250 [1:45:02<35:15:20, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 293: train loss 4.86327. lr 1.411200e-04:   5%|▍         | 294/6250 [1:45:02<35:23:34, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 294: train loss 4.93867. lr 1.416000e-04:   5%|▍         | 294/6250 [1:45:23<35:23:34, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 294: train loss 4.93867. lr 1.416000e-04:   5%|▍         | 295/6250 [1:45:23<35:26:39, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 295: train loss 4.97864. lr 1.420800e-04:   5%|▍         | 295/6250 [1:45:44<35:26:39, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 295: train loss 4.97864. lr 1.420800e-04:   5%|▍         | 296/6250 [1:45:44<35:14:43, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 296: train loss 4.74377. lr 1.425600e-04:   5%|▍         | 296/6250 [1:46:06<35:14:43, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 296: train loss 4.74377. lr 1.425600e-04:   5%|▍         | 297/6250 [1:46:06<35:28:54, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 297: train loss 5.05946. lr 1.430400e-04:   5%|▍         | 297/6250 [1:46:27<35:28:54, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 297: train loss 5.05946. lr 1.430400e-04:   5%|▍         | 298/6250 [1:46:27<35:30:51, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 298: train loss 4.88771. lr 1.435200e-04:   5%|▍         | 298/6250 [1:46:48<35:30:51, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 298: train loss 4.88771. lr 1.435200e-04:   5%|▍         | 299/6250 [1:46:48<35:12:57, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 299: train loss 4.87099. lr 1.440000e-04:   5%|▍         | 299/6250 [1:47:10<35:12:57, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 299: train loss 4.87099. lr 1.440000e-04:   5%|▍         | 300/6250 [1:47:10<35:32:16, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 300: train loss 4.81805. lr 1.444800e-04:   5%|▍         | 300/6250 [1:47:32<35:32:16, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 300: train loss 4.81805. lr 1.444800e-04:   5%|▍         | 301/6250 [1:47:32<35:27:37, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 301: train loss 4.93682. lr 1.449600e-04:   5%|▍         | 301/6250 [1:47:53<35:27:37, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 301: train loss 4.93682. lr 1.449600e-04:   5%|▍         | 302/6250 [1:47:53<35:26:27, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 302: train loss 4.87557. lr 1.454400e-04:   5%|▍         | 302/6250 [1:48:15<35:26:27, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 302: train loss 4.87557. lr 1.454400e-04:   5%|▍         | 303/6250 [1:48:15<35:35:09, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 303: train loss 4.86105. lr 1.459200e-04:   5%|▍         | 303/6250 [1:48:36<35:35:09, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 303: train loss 4.86105. lr 1.459200e-04:   5%|▍         | 304/6250 [1:48:36<35:31:40, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 304: train loss 4.97834. lr 1.464000e-04:   5%|▍         | 304/6250 [1:48:58<35:31:40, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 304: train loss 4.97834. lr 1.464000e-04:   5%|▍         | 305/6250 [1:48:58<35:45:08, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 305: train loss 4.81590. lr 1.468800e-04:   5%|▍         | 305/6250 [1:49:20<35:45:08, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 305: train loss 4.81590. lr 1.468800e-04:   5%|▍         | 306/6250 [1:49:20<35:38:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 306: train loss 4.91537. lr 1.473600e-04:   5%|▍         | 306/6250 [1:49:41<35:38:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 306: train loss 4.91537. lr 1.473600e-04:   5%|▍         | 307/6250 [1:49:41<35:26:02, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 307: train loss 4.71051. lr 1.478400e-04:   5%|▍         | 307/6250 [1:50:03<35:26:02, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 307: train loss 4.71051. lr 1.478400e-04:   5%|▍         | 308/6250 [1:50:03<35:38:43, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 308: train loss 4.82083. lr 1.483200e-04:   5%|▍         | 308/6250 [1:50:24<35:38:43, 21.60s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 308: train loss 4.82083. lr 1.483200e-04:   5%|▍         | 309/6250 [1:50:24<35:26:23, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 309: train loss 4.66289. lr 1.488000e-04:   5%|▍         | 309/6250 [1:50:45<35:26:23, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 309: train loss 4.66289. lr 1.488000e-04:   5%|▍         | 310/6250 [1:50:45<35:21:19, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 310: train loss 4.61985. lr 1.492800e-04:   5%|▍         | 310/6250 [1:51:07<35:21:19, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 310: train loss 4.61985. lr 1.492800e-04:   5%|▍         | 311/6250 [1:51:07<35:36:53, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 311: train loss 4.82708. lr 1.497600e-04:   5%|▍         | 311/6250 [1:51:28<35:36:53, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 311: train loss 4.82708. lr 1.497600e-04:   5%|▍         | 312/6250 [1:51:28<35:26:34, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 312: train loss 4.77530. lr 1.502400e-04:   5%|▍         | 312/6250 [1:51:50<35:26:34, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 312: train loss 4.77530. lr 1.502400e-04:   5%|▌         | 313/6250 [1:51:50<35:22:04, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 313: train loss 4.75448. lr 1.507200e-04:   5%|▌         | 313/6250 [1:52:12<35:22:04, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 313: train loss 4.75448. lr 1.507200e-04:   5%|▌         | 314/6250 [1:52:12<35:40:52, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 314: train loss 4.80159. lr 1.512000e-04:   5%|▌         | 314/6250 [1:52:33<35:40:52, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 314: train loss 4.80159. lr 1.512000e-04:   5%|▌         | 315/6250 [1:52:33<35:17:36, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 315: train loss 4.82508. lr 1.516800e-04:   5%|▌         | 315/6250 [1:52:54<35:17:36, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 315: train loss 4.82508. lr 1.516800e-04:   5%|▌         | 316/6250 [1:52:54<35:19:03, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 316: train loss 4.70825. lr 1.521600e-04:   5%|▌         | 316/6250 [1:53:16<35:19:03, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 316: train loss 4.70825. lr 1.521600e-04:   5%|▌         | 317/6250 [1:53:16<35:33:12, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 317: train loss 4.72678. lr 1.526400e-04:   5%|▌         | 317/6250 [1:53:37<35:33:12, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 317: train loss 4.72678. lr 1.526400e-04:   5%|▌         | 318/6250 [1:53:37<35:14:34, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 318: train loss 4.81302. lr 1.531200e-04:   5%|▌         | 318/6250 [1:53:59<35:14:34, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 318: train loss 4.81302. lr 1.531200e-04:   5%|▌         | 319/6250 [1:53:59<35:16:07, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 319: train loss 4.65227. lr 1.536000e-04:   5%|▌         | 319/6250 [1:54:20<35:16:07, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 319: train loss 4.65227. lr 1.536000e-04:   5%|▌         | 320/6250 [1:54:20<35:26:24, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 320: train loss 4.81559. lr 1.540800e-04:   5%|▌         | 320/6250 [1:54:41<35:26:24, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 320: train loss 4.81559. lr 1.540800e-04:   5%|▌         | 321/6250 [1:54:41<35:05:38, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 321: train loss 4.59907. lr 1.545600e-04:   5%|▌         | 321/6250 [1:55:03<35:05:38, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 321: train loss 4.59907. lr 1.545600e-04:   5%|▌         | 322/6250 [1:55:03<35:09:08, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 322: train loss 4.94630. lr 1.550400e-04:   5%|▌         | 322/6250 [1:55:24<35:09:08, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 322: train loss 4.94630. lr 1.550400e-04:   5%|▌         | 323/6250 [1:55:24<35:17:23, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 323: train loss 4.69061. lr 1.555200e-04:   5%|▌         | 323/6250 [1:55:46<35:17:23, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 323: train loss 4.69061. lr 1.555200e-04:   5%|▌         | 324/6250 [1:55:46<35:14:48, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 324: train loss 4.44567. lr 1.560000e-04:   5%|▌         | 324/6250 [1:56:07<35:14:48, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 324: train loss 4.44567. lr 1.560000e-04:   5%|▌         | 325/6250 [1:56:07<35:27:33, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 325: train loss 4.87463. lr 1.564800e-04:   5%|▌         | 325/6250 [1:56:29<35:27:33, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 325: train loss 4.87463. lr 1.564800e-04:   5%|▌         | 326/6250 [1:56:29<35:19:32, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 326: train loss 4.85399. lr 1.569600e-04:   5%|▌         | 326/6250 [1:56:50<35:19:32, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 326: train loss 4.85399. lr 1.569600e-04:   5%|▌         | 327/6250 [1:56:50<35:19:41, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 327: train loss 4.72909. lr 1.574400e-04:   5%|▌         | 327/6250 [1:57:12<35:19:41, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 327: train loss 4.72909. lr 1.574400e-04:   5%|▌         | 328/6250 [1:57:12<35:35:54, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 328: train loss 4.95467. lr 1.579200e-04:   5%|▌         | 328/6250 [1:57:34<35:35:54, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 328: train loss 4.95467. lr 1.579200e-04:   5%|▌         | 329/6250 [1:57:34<35:28:50, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 329: train loss 4.66791. lr 1.584000e-04:   5%|▌         | 329/6250 [1:57:55<35:28:50, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 329: train loss 4.66791. lr 1.584000e-04:   5%|▌         | 330/6250 [1:57:55<35:15:29, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 330: train loss 4.63010. lr 1.588800e-04:   5%|▌         | 330/6250 [1:58:17<35:15:29, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 330: train loss 4.63010. lr 1.588800e-04:   5%|▌         | 331/6250 [1:58:17<35:28:04, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 331: train loss 4.42995. lr 1.593600e-04:   5%|▌         | 331/6250 [1:58:38<35:28:04, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 331: train loss 4.42995. lr 1.593600e-04:   5%|▌         | 332/6250 [1:58:38<35:19:43, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 332: train loss 4.68262. lr 1.598400e-04:   5%|▌         | 332/6250 [1:58:59<35:19:43, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 332: train loss 4.68262. lr 1.598400e-04:   5%|▌         | 333/6250 [1:58:59<35:14:33, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 333: train loss 4.65642. lr 1.603200e-04:   5%|▌         | 333/6250 [1:59:21<35:14:33, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 333: train loss 4.65642. lr 1.603200e-04:   5%|▌         | 334/6250 [1:59:21<35:17:24, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 334: train loss 4.59162. lr 1.608000e-04:   5%|▌         | 334/6250 [1:59:42<35:17:24, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 334: train loss 4.59162. lr 1.608000e-04:   5%|▌         | 335/6250 [1:59:42<35:08:35, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 335: train loss 4.60622. lr 1.612800e-04:   5%|▌         | 335/6250 [2:00:04<35:08:35, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 335: train loss 4.60622. lr 1.612800e-04:   5%|▌         | 336/6250 [2:00:04<35:20:13, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 336: train loss 4.50095. lr 1.617600e-04:   5%|▌         | 336/6250 [2:00:25<35:20:13, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 336: train loss 4.50095. lr 1.617600e-04:   5%|▌         | 337/6250 [2:00:25<35:20:24, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 337: train loss 4.76600. lr 1.622400e-04:   5%|▌         | 337/6250 [2:00:47<35:20:24, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 337: train loss 4.76600. lr 1.622400e-04:   5%|▌         | 338/6250 [2:00:47<35:21:22, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 338: train loss 4.63242. lr 1.627200e-04:   5%|▌         | 338/6250 [2:01:09<35:21:22, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 338: train loss 4.63242. lr 1.627200e-04:   5%|▌         | 339/6250 [2:01:09<35:31:58, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 339: train loss 4.70479. lr 1.632000e-04:   5%|▌         | 339/6250 [2:01:31<35:31:58, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 339: train loss 4.70479. lr 1.632000e-04:   5%|▌         | 340/6250 [2:01:31<35:33:44, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 340: train loss 4.57246. lr 1.636800e-04:   5%|▌         | 340/6250 [2:01:52<35:33:44, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 340: train loss 4.57246. lr 1.636800e-04:   5%|▌         | 341/6250 [2:01:52<35:25:49, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 341: train loss 4.57022. lr 1.641600e-04:   5%|▌         | 341/6250 [2:02:14<35:25:49, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 341: train loss 4.57022. lr 1.641600e-04:   5%|▌         | 342/6250 [2:02:14<35:48:02, 21.81s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 342: train loss 4.50161. lr 1.646400e-04:   5%|▌         | 342/6250 [2:02:36<35:48:02, 21.81s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 342: train loss 4.50161. lr 1.646400e-04:   5%|▌         | 343/6250 [2:02:36<35:34:04, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 343: train loss 4.57429. lr 1.651200e-04:   5%|▌         | 343/6250 [2:02:57<35:34:04, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 343: train loss 4.57429. lr 1.651200e-04:   6%|▌         | 344/6250 [2:02:57<35:23:28, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 344: train loss 4.55651. lr 1.656000e-04:   6%|▌         | 344/6250 [2:03:19<35:23:28, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 344: train loss 4.55651. lr 1.656000e-04:   6%|▌         | 345/6250 [2:03:19<35:28:18, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 345: train loss 4.48260. lr 1.660800e-04:   6%|▌         | 345/6250 [2:03:40<35:28:18, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 345: train loss 4.48260. lr 1.660800e-04:   6%|▌         | 346/6250 [2:03:40<35:17:42, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 346: train loss 4.56987. lr 1.665600e-04:   6%|▌         | 346/6250 [2:04:02<35:17:42, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 346: train loss 4.56987. lr 1.665600e-04:   6%|▌         | 347/6250 [2:04:02<35:26:48, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 347: train loss 4.68966. lr 1.670400e-04:   6%|▌         | 347/6250 [2:04:23<35:26:48, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 347: train loss 4.68966. lr 1.670400e-04:   6%|▌         | 348/6250 [2:04:23<35:19:17, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 348: train loss 4.52773. lr 1.675200e-04:   6%|▌         | 348/6250 [2:04:45<35:19:17, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 348: train loss 4.52773. lr 1.675200e-04:   6%|▌         | 349/6250 [2:04:45<35:12:07, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 349: train loss 4.31687. lr 1.680000e-04:   6%|▌         | 349/6250 [2:05:07<35:12:07, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 349: train loss 4.31687. lr 1.680000e-04:   6%|▌         | 350/6250 [2:05:07<35:29:04, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 350: train loss 4.28474. lr 1.684800e-04:   6%|▌         | 350/6250 [2:05:28<35:29:04, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 350: train loss 4.28474. lr 1.684800e-04:   6%|▌         | 351/6250 [2:05:28<35:13:56, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 351: train loss 4.51210. lr 1.689600e-04:   6%|▌         | 351/6250 [2:05:49<35:13:56, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 351: train loss 4.51210. lr 1.689600e-04:   6%|▌         | 352/6250 [2:05:49<35:06:37, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 352: train loss 4.54664. lr 1.694400e-04:   6%|▌         | 352/6250 [2:06:11<35:06:37, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 352: train loss 4.54664. lr 1.694400e-04:   6%|▌         | 353/6250 [2:06:11<35:17:44, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 353: train loss 4.68096. lr 1.699200e-04:   6%|▌         | 353/6250 [2:06:32<35:17:44, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 353: train loss 4.68096. lr 1.699200e-04:   6%|▌         | 354/6250 [2:06:32<35:01:13, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 354: train loss 4.57634. lr 1.704000e-04:   6%|▌         | 354/6250 [2:06:53<35:01:13, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 354: train loss 4.57634. lr 1.704000e-04:   6%|▌         | 355/6250 [2:06:53<35:01:56, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 355: train loss 4.28436. lr 1.708800e-04:   6%|▌         | 355/6250 [2:07:16<35:01:56, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 355: train loss 4.28436. lr 1.708800e-04:   6%|▌         | 356/6250 [2:07:16<35:32:14, 21.71s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 356: train loss 4.49141. lr 1.713600e-04:   6%|▌         | 356/6250 [2:07:37<35:32:14, 21.71s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 356: train loss 4.49141. lr 1.713600e-04:   6%|▌         | 357/6250 [2:07:37<35:22:52, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 357: train loss 4.64339. lr 1.718400e-04:   6%|▌         | 357/6250 [2:07:59<35:22:52, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 357: train loss 4.64339. lr 1.718400e-04:   6%|▌         | 358/6250 [2:07:59<35:21:53, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 358: train loss 4.52542. lr 1.723200e-04:   6%|▌         | 358/6250 [2:08:20<35:21:53, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 358: train loss 4.52542. lr 1.723200e-04:   6%|▌         | 359/6250 [2:08:20<35:18:45, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 359: train loss 4.55082. lr 1.728000e-04:   6%|▌         | 359/6250 [2:08:41<35:18:45, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 359: train loss 4.55082. lr 1.728000e-04:   6%|▌         | 360/6250 [2:08:41<35:00:08, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 360: train loss 4.38724. lr 1.732800e-04:   6%|▌         | 360/6250 [2:09:03<35:00:08, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 360: train loss 4.38724. lr 1.732800e-04:   6%|▌         | 361/6250 [2:09:03<35:10:54, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 361: train loss 4.40752. lr 1.737600e-04:   6%|▌         | 361/6250 [2:09:24<35:10:54, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 361: train loss 4.40752. lr 1.737600e-04:   6%|▌         | 362/6250 [2:09:24<35:04:02, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 362: train loss 4.35468. lr 1.742400e-04:   6%|▌         | 362/6250 [2:09:45<35:04:02, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 362: train loss 4.35468. lr 1.742400e-04:   6%|▌         | 363/6250 [2:09:45<34:45:15, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 363: train loss 4.40562. lr 1.747200e-04:   6%|▌         | 363/6250 [2:10:07<34:45:15, 21.25s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 363: train loss 4.40562. lr 1.747200e-04:   6%|▌         | 364/6250 [2:10:07<35:02:25, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 364: train loss 4.38108. lr 1.752000e-04:   6%|▌         | 364/6250 [2:10:28<35:02:25, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 364: train loss 4.38108. lr 1.752000e-04:   6%|▌         | 365/6250 [2:10:28<34:56:56, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 365: train loss 4.47542. lr 1.756800e-04:   6%|▌         | 365/6250 [2:10:49<34:56:56, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 365: train loss 4.47542. lr 1.756800e-04:   6%|▌         | 366/6250 [2:10:49<34:51:35, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 366: train loss 4.49979. lr 1.761600e-04:   6%|▌         | 366/6250 [2:11:11<34:51:35, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 366: train loss 4.49979. lr 1.761600e-04:   6%|▌         | 367/6250 [2:11:11<35:04:59, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 367: train loss 4.57987. lr 1.766400e-04:   6%|▌         | 367/6250 [2:11:33<35:04:59, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 367: train loss 4.57987. lr 1.766400e-04:   6%|▌         | 368/6250 [2:11:33<35:00:40, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 368: train loss 4.37628. lr 1.771200e-04:   6%|▌         | 368/6250 [2:11:53<35:00:40, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 368: train loss 4.37628. lr 1.771200e-04:   6%|▌         | 369/6250 [2:11:53<34:44:07, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 369: train loss 4.47134. lr 1.776000e-04:   6%|▌         | 369/6250 [2:12:16<34:44:07, 21.26s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 369: train loss 4.47134. lr 1.776000e-04:   6%|▌         | 370/6250 [2:12:16<35:10:12, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 370: train loss 4.52470. lr 1.780800e-04:   6%|▌         | 370/6250 [2:12:37<35:10:12, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 370: train loss 4.52470. lr 1.780800e-04:   6%|▌         | 371/6250 [2:12:37<35:18:20, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 371: train loss 4.35391. lr 1.785600e-04:   6%|▌         | 371/6250 [2:12:59<35:18:20, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 371: train loss 4.35391. lr 1.785600e-04:   6%|▌         | 372/6250 [2:12:59<35:27:43, 21.72s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 372: train loss 4.25722. lr 1.790400e-04:   6%|▌         | 372/6250 [2:13:21<35:27:43, 21.72s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 372: train loss 4.25722. lr 1.790400e-04:   6%|▌         | 373/6250 [2:13:21<35:20:25, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 373: train loss 4.26616. lr 1.795200e-04:   6%|▌         | 373/6250 [2:13:42<35:20:25, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 373: train loss 4.26616. lr 1.795200e-04:   6%|▌         | 374/6250 [2:13:42<35:08:39, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 374: train loss 4.34732. lr 1.800000e-04:   6%|▌         | 374/6250 [2:14:04<35:08:39, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 374: train loss 4.34732. lr 1.800000e-04:   6%|▌         | 375/6250 [2:14:04<35:19:09, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 375: train loss 4.09152. lr 1.804800e-04:   6%|▌         | 375/6250 [2:14:25<35:19:09, 21.64s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 375: train loss 4.09152. lr 1.804800e-04:   6%|▌         | 376/6250 [2:14:25<35:09:10, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 376: train loss 4.37664. lr 1.809600e-04:   6%|▌         | 376/6250 [2:14:46<35:09:10, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 376: train loss 4.37664. lr 1.809600e-04:   6%|▌         | 377/6250 [2:14:46<34:57:16, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 377: train loss 4.45323. lr 1.814400e-04:   6%|▌         | 377/6250 [2:15:08<34:57:16, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 377: train loss 4.45323. lr 1.814400e-04:   6%|▌         | 378/6250 [2:15:08<35:09:49, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 378: train loss 4.02957. lr 1.819200e-04:   6%|▌         | 378/6250 [2:15:30<35:09:49, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 378: train loss 4.02957. lr 1.819200e-04:   6%|▌         | 379/6250 [2:15:30<35:04:18, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 379: train loss 4.39678. lr 1.824000e-04:   6%|▌         | 379/6250 [2:15:51<35:04:18, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 379: train loss 4.39678. lr 1.824000e-04:   6%|▌         | 380/6250 [2:15:51<35:03:11, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 380: train loss 4.47190. lr 1.828800e-04:   6%|▌         | 380/6250 [2:16:13<35:03:11, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 380: train loss 4.47190. lr 1.828800e-04:   6%|▌         | 381/6250 [2:16:13<35:10:20, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 381: train loss 4.39613. lr 1.833600e-04:   6%|▌         | 381/6250 [2:16:34<35:10:20, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 381: train loss 4.39613. lr 1.833600e-04:   6%|▌         | 382/6250 [2:16:34<35:06:11, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 382: train loss 4.38455. lr 1.838400e-04:   6%|▌         | 382/6250 [2:16:56<35:06:11, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 382: train loss 4.38455. lr 1.838400e-04:   6%|▌         | 383/6250 [2:16:56<35:01:26, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 383: train loss 4.40699. lr 1.843200e-04:   6%|▌         | 383/6250 [2:17:18<35:01:26, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 383: train loss 4.40699. lr 1.843200e-04:   6%|▌         | 384/6250 [2:17:18<35:17:27, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 384: train loss 4.51046. lr 1.848000e-04:   6%|▌         | 384/6250 [2:17:39<35:17:27, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 384: train loss 4.51046. lr 1.848000e-04:   6%|▌         | 385/6250 [2:17:39<34:58:14, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 385: train loss 4.27293. lr 1.852800e-04:   6%|▌         | 385/6250 [2:18:01<34:58:14, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 385: train loss 4.27293. lr 1.852800e-04:   6%|▌         | 386/6250 [2:18:01<35:19:10, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 386: train loss 4.16831. lr 1.857600e-04:   6%|▌         | 386/6250 [2:18:23<35:19:10, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 386: train loss 4.16831. lr 1.857600e-04:   6%|▌         | 387/6250 [2:18:23<35:15:56, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 387: train loss 4.38118. lr 1.862400e-04:   6%|▌         | 387/6250 [2:18:44<35:15:56, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 387: train loss 4.38118. lr 1.862400e-04:   6%|▌         | 388/6250 [2:18:44<34:57:13, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 388: train loss 4.41586. lr 1.867200e-04:   6%|▌         | 388/6250 [2:19:05<34:57:13, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 388: train loss 4.41586. lr 1.867200e-04:   6%|▌         | 389/6250 [2:19:05<35:08:26, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 389: train loss 4.34491. lr 1.872000e-04:   6%|▌         | 389/6250 [2:19:27<35:08:26, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 389: train loss 4.34491. lr 1.872000e-04:   6%|▌         | 390/6250 [2:19:27<35:00:17, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 390: train loss 4.50811. lr 1.876800e-04:   6%|▌         | 390/6250 [2:19:48<35:00:17, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 390: train loss 4.50811. lr 1.876800e-04:   6%|▋         | 391/6250 [2:19:48<34:50:55, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 391: train loss 4.02094. lr 1.881600e-04:   6%|▋         | 391/6250 [2:20:10<34:50:55, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 391: train loss 4.02094. lr 1.881600e-04:   6%|▋         | 392/6250 [2:20:10<35:02:31, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 392: train loss 4.10799. lr 1.886400e-04:   6%|▋         | 392/6250 [2:20:31<35:02:31, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 392: train loss 4.10799. lr 1.886400e-04:   6%|▋         | 393/6250 [2:20:31<34:48:19, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 393: train loss 4.33896. lr 1.891200e-04:   6%|▋         | 393/6250 [2:20:52<34:48:19, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 393: train loss 4.33896. lr 1.891200e-04:   6%|▋         | 394/6250 [2:20:52<34:39:54, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 394: train loss 4.32587. lr 1.896000e-04:   6%|▋         | 394/6250 [2:21:14<34:39:54, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 394: train loss 4.32587. lr 1.896000e-04:   6%|▋         | 395/6250 [2:21:14<34:58:06, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 395: train loss 4.42726. lr 1.900800e-04:   6%|▋         | 395/6250 [2:21:35<34:58:06, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 395: train loss 4.42726. lr 1.900800e-04:   6%|▋         | 396/6250 [2:21:35<34:49:07, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 396: train loss 3.84489. lr 1.905600e-04:   6%|▋         | 396/6250 [2:21:56<34:49:07, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 396: train loss 3.84489. lr 1.905600e-04:   6%|▋         | 397/6250 [2:21:56<34:36:34, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 397: train loss 4.41736. lr 1.910400e-04:   6%|▋         | 397/6250 [2:22:18<34:36:34, 21.29s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 397: train loss 4.41736. lr 1.910400e-04:   6%|▋         | 398/6250 [2:22:18<34:51:31, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 398: train loss 4.11810. lr 1.915200e-04:   6%|▋         | 398/6250 [2:22:39<34:51:31, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 398: train loss 4.11810. lr 1.915200e-04:   6%|▋         | 399/6250 [2:22:39<34:36:51, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 399: train loss 4.35885. lr 1.920000e-04:   6%|▋         | 399/6250 [2:23:00<34:36:51, 21.30s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 399: train loss 4.35885. lr 1.920000e-04:   6%|▋         | 400/6250 [2:23:00<34:44:19, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 400: train loss 4.27397. lr 1.924800e-04:   6%|▋         | 400/6250 [2:23:22<34:44:19, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 400: train loss 4.27397. lr 1.924800e-04:   6%|▋         | 401/6250 [2:23:22<34:53:02, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 401: train loss 4.18057. lr 1.929600e-04:   6%|▋         | 401/6250 [2:23:43<34:53:02, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 401: train loss 4.18057. lr 1.929600e-04:   6%|▋         | 402/6250 [2:23:43<34:46:42, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 402: train loss 4.39412. lr 1.934400e-04:   6%|▋         | 402/6250 [2:24:05<34:46:42, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 402: train loss 4.39412. lr 1.934400e-04:   6%|▋         | 403/6250 [2:24:05<34:52:49, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 403: train loss 4.27578. lr 1.939200e-04:   6%|▋         | 403/6250 [2:24:27<34:52:49, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 403: train loss 4.27578. lr 1.939200e-04:   6%|▋         | 404/6250 [2:24:27<34:55:11, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 404: train loss 4.10082. lr 1.944000e-04:   6%|▋         | 404/6250 [2:24:48<34:55:11, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 404: train loss 4.10082. lr 1.944000e-04:   6%|▋         | 405/6250 [2:24:48<34:47:22, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 405: train loss 4.17686. lr 1.948800e-04:   6%|▋         | 405/6250 [2:25:10<34:47:22, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 405: train loss 4.17686. lr 1.948800e-04:   6%|▋         | 406/6250 [2:25:10<35:02:22, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 406: train loss 4.18670. lr 1.953600e-04:   6%|▋         | 406/6250 [2:25:31<35:02:22, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 406: train loss 4.18670. lr 1.953600e-04:   7%|▋         | 407/6250 [2:25:31<34:51:37, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 407: train loss 4.29892. lr 1.958400e-04:   7%|▋         | 407/6250 [2:25:52<34:51:37, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 407: train loss 4.29892. lr 1.958400e-04:   7%|▋         | 408/6250 [2:25:52<34:48:35, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 408: train loss 4.13022. lr 1.963200e-04:   7%|▋         | 408/6250 [2:26:14<34:48:35, 21.45s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 408: train loss 4.13022. lr 1.963200e-04:   7%|▋         | 409/6250 [2:26:14<34:54:30, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 409: train loss 4.32767. lr 1.968000e-04:   7%|▋         | 409/6250 [2:26:35<34:54:30, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 409: train loss 4.32767. lr 1.968000e-04:   7%|▋         | 410/6250 [2:26:35<34:46:58, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 410: train loss 4.08313. lr 1.972800e-04:   7%|▋         | 410/6250 [2:26:57<34:46:58, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 410: train loss 4.08313. lr 1.972800e-04:   7%|▋         | 411/6250 [2:26:57<34:43:55, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 411: train loss 4.25766. lr 1.977600e-04:   7%|▋         | 411/6250 [2:27:19<34:43:55, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 411: train loss 4.25766. lr 1.977600e-04:   7%|▋         | 412/6250 [2:27:19<34:56:24, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 412: train loss 4.19166. lr 1.982400e-04:   7%|▋         | 412/6250 [2:27:40<34:56:24, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 412: train loss 4.19166. lr 1.982400e-04:   7%|▋         | 413/6250 [2:27:40<34:48:38, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 413: train loss 4.26011. lr 1.987200e-04:   7%|▋         | 413/6250 [2:28:02<34:48:38, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 413: train loss 4.26011. lr 1.987200e-04:   7%|▋         | 414/6250 [2:28:02<34:55:33, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 414: train loss 3.93009. lr 1.992000e-04:   7%|▋         | 414/6250 [2:28:23<34:55:33, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 414: train loss 3.93009. lr 1.992000e-04:   7%|▋         | 415/6250 [2:28:23<34:48:49, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 415: train loss 4.29589. lr 1.996800e-04:   7%|▋         | 415/6250 [2:28:44<34:48:49, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 415: train loss 4.29589. lr 1.996800e-04:   7%|▋         | 416/6250 [2:28:44<34:50:03, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 416: train loss 4.33420. lr 2.001600e-04:   7%|▋         | 416/6250 [2:29:06<34:50:03, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 416: train loss 4.33420. lr 2.001600e-04:   7%|▋         | 417/6250 [2:29:06<34:54:20, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 417: train loss 4.09380. lr 2.006400e-04:   7%|▋         | 417/6250 [2:29:27<34:54:20, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 417: train loss 4.09380. lr 2.006400e-04:   7%|▋         | 418/6250 [2:29:27<34:42:15, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 418: train loss 4.14894. lr 2.011200e-04:   7%|▋         | 418/6250 [2:29:48<34:42:15, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 418: train loss 4.14894. lr 2.011200e-04:   7%|▋         | 419/6250 [2:29:48<34:33:09, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 419: train loss 4.15285. lr 2.016000e-04:   7%|▋         | 419/6250 [2:30:10<34:33:09, 21.33s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 419: train loss 4.15285. lr 2.016000e-04:   7%|▋         | 420/6250 [2:30:10<34:51:45, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 420: train loss 4.26460. lr 2.020800e-04:   7%|▋         | 420/6250 [2:30:31<34:51:45, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 420: train loss 4.26460. lr 2.020800e-04:   7%|▋         | 421/6250 [2:30:31<34:37:14, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 421: train loss 3.86887. lr 2.025600e-04:   7%|▋         | 421/6250 [2:30:53<34:37:14, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 421: train loss 3.86887. lr 2.025600e-04:   7%|▋         | 422/6250 [2:30:53<34:33:47, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 422: train loss 4.19283. lr 2.030400e-04:   7%|▋         | 422/6250 [2:31:15<34:33:47, 21.35s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 422: train loss 4.19283. lr 2.030400e-04:   7%|▋         | 423/6250 [2:31:15<34:49:52, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 423: train loss 4.09914. lr 2.035200e-04:   7%|▋         | 423/6250 [2:31:35<34:49:52, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 423: train loss 4.09914. lr 2.035200e-04:   7%|▋         | 424/6250 [2:31:35<34:32:00, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 424: train loss 4.12463. lr 2.040000e-04:   7%|▋         | 424/6250 [2:31:57<34:32:00, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 424: train loss 4.12463. lr 2.040000e-04:   7%|▋         | 425/6250 [2:31:57<34:28:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 425: train loss 4.10756. lr 2.044800e-04:   7%|▋         | 425/6250 [2:32:19<34:28:57, 21.31s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 425: train loss 4.10756. lr 2.044800e-04:   7%|▋         | 426/6250 [2:32:19<34:46:28, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 426: train loss 4.19362. lr 2.049600e-04:   7%|▋         | 426/6250 [2:32:40<34:46:28, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 426: train loss 4.19362. lr 2.049600e-04:   7%|▋         | 427/6250 [2:32:40<34:31:21, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 427: train loss 4.13315. lr 2.054400e-04:   7%|▋         | 427/6250 [2:33:01<34:31:21, 21.34s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 427: train loss 4.13315. lr 2.054400e-04:   7%|▋         | 428/6250 [2:33:01<34:45:37, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 428: train loss 3.94180. lr 2.059200e-04:   7%|▋         | 428/6250 [2:33:23<34:45:37, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 428: train loss 3.94180. lr 2.059200e-04:   7%|▋         | 429/6250 [2:33:23<34:45:54, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 429: train loss 4.12409. lr 2.064000e-04:   7%|▋         | 429/6250 [2:33:44<34:45:54, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 429: train loss 4.12409. lr 2.064000e-04:   7%|▋         | 430/6250 [2:33:44<34:35:20, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 430: train loss 4.03859. lr 2.068800e-04:   7%|▋         | 430/6250 [2:34:06<34:35:20, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 430: train loss 4.03859. lr 2.068800e-04:   7%|▋         | 431/6250 [2:34:06<35:00:04, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 431: train loss 4.14534. lr 2.073600e-04:   7%|▋         | 431/6250 [2:34:28<35:00:04, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 431: train loss 4.14534. lr 2.073600e-04:   7%|▋         | 432/6250 [2:34:28<34:52:34, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 432: train loss 4.06223. lr 2.078400e-04:   7%|▋         | 432/6250 [2:34:49<34:52:34, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 432: train loss 4.06223. lr 2.078400e-04:   7%|▋         | 433/6250 [2:34:49<34:44:32, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 433: train loss 3.83772. lr 2.083200e-04:   7%|▋         | 433/6250 [2:35:11<34:44:32, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 433: train loss 3.83772. lr 2.083200e-04:   7%|▋         | 434/6250 [2:35:11<34:59:38, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 434: train loss 4.16758. lr 2.088000e-04:   7%|▋         | 434/6250 [2:35:32<34:59:38, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 434: train loss 4.16758. lr 2.088000e-04:   7%|▋         | 435/6250 [2:35:32<34:48:30, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 435: train loss 4.03232. lr 2.092800e-04:   7%|▋         | 435/6250 [2:35:54<34:48:30, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 435: train loss 4.03232. lr 2.092800e-04:   7%|▋         | 436/6250 [2:35:54<34:36:32, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 436: train loss 4.07118. lr 2.097600e-04:   7%|▋         | 436/6250 [2:36:16<34:36:32, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 436: train loss 4.07118. lr 2.097600e-04:   7%|▋         | 437/6250 [2:36:16<34:53:25, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 437: train loss 4.14316. lr 2.102400e-04:   7%|▋         | 437/6250 [2:36:37<34:53:25, 21.61s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 437: train loss 4.14316. lr 2.102400e-04:   7%|▋         | 438/6250 [2:36:37<34:40:23, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 438: train loss 4.02449. lr 2.107200e-04:   7%|▋         | 438/6250 [2:36:58<34:40:23, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 438: train loss 4.02449. lr 2.107200e-04:   7%|▋         | 439/6250 [2:36:58<34:33:54, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 439: train loss 4.13214. lr 2.112000e-04:   7%|▋         | 439/6250 [2:37:20<34:33:54, 21.41s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 439: train loss 4.13214. lr 2.112000e-04:   7%|▋         | 440/6250 [2:37:20<34:44:53, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 440: train loss 4.07961. lr 2.116800e-04:   7%|▋         | 440/6250 [2:37:41<34:44:53, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 440: train loss 4.07961. lr 2.116800e-04:   7%|▋         | 441/6250 [2:37:41<34:39:45, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 441: train loss 4.21335. lr 2.121600e-04:   7%|▋         | 441/6250 [2:38:03<34:39:45, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 441: train loss 4.21335. lr 2.121600e-04:   7%|▋         | 442/6250 [2:38:03<34:44:17, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 442: train loss 4.14728. lr 2.126400e-04:   7%|▋         | 442/6250 [2:38:24<34:44:17, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 442: train loss 4.14728. lr 2.126400e-04:   7%|▋         | 443/6250 [2:38:24<34:39:29, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 443: train loss 4.07679. lr 2.131200e-04:   7%|▋         | 443/6250 [2:38:46<34:39:29, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 443: train loss 4.07679. lr 2.131200e-04:   7%|▋         | 444/6250 [2:38:46<34:33:27, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 444: train loss 4.22528. lr 2.136000e-04:   7%|▋         | 444/6250 [2:39:07<34:33:27, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 444: train loss 4.22528. lr 2.136000e-04:   7%|▋         | 445/6250 [2:39:07<34:46:32, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 445: train loss 3.77111. lr 2.140800e-04:   7%|▋         | 445/6250 [2:39:29<34:46:32, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 445: train loss 3.77111. lr 2.140800e-04:   7%|▋         | 446/6250 [2:39:29<34:43:24, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 446: train loss 4.02462. lr 2.145600e-04:   7%|▋         | 446/6250 [2:39:51<34:43:24, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 446: train loss 4.02462. lr 2.145600e-04:   7%|▋         | 447/6250 [2:39:51<34:45:54, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 447: train loss 4.12520. lr 2.150400e-04:   7%|▋         | 447/6250 [2:40:12<34:45:54, 21.57s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 447: train loss 4.12520. lr 2.150400e-04:   7%|▋         | 448/6250 [2:40:12<34:50:51, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 448: train loss 3.94671. lr 2.155200e-04:   7%|▋         | 448/6250 [2:40:33<34:50:51, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 448: train loss 3.94671. lr 2.155200e-04:   7%|▋         | 449/6250 [2:40:34<34:37:48, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 449: train loss 3.90508. lr 2.160000e-04:   7%|▋         | 449/6250 [2:40:55<34:37:48, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 449: train loss 3.90508. lr 2.160000e-04:   7%|▋         | 450/6250 [2:40:55<34:31:45, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 450: train loss 3.89656. lr 2.164800e-04:   7%|▋         | 450/6250 [2:41:17<34:31:45, 21.43s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 450: train loss 3.89656. lr 2.164800e-04:   7%|▋         | 451/6250 [2:41:17<34:42:36, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 451: train loss 3.79600. lr 2.169600e-04:   7%|▋         | 451/6250 [2:41:38<34:42:36, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 451: train loss 3.79600. lr 2.169600e-04:   7%|▋         | 452/6250 [2:41:38<34:31:22, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 452: train loss 4.17087. lr 2.174400e-04:   7%|▋         | 452/6250 [2:42:00<34:31:22, 21.44s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 452: train loss 4.17087. lr 2.174400e-04:   7%|▋         | 453/6250 [2:42:00<34:39:30, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 453: train loss 3.87507. lr 2.179200e-04:   7%|▋         | 453/6250 [2:42:21<34:39:30, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 453: train loss 3.87507. lr 2.179200e-04:   7%|▋         | 454/6250 [2:42:21<34:34:07, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 454: train loss 4.07168. lr 2.184000e-04:   7%|▋         | 454/6250 [2:42:42<34:34:07, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 454: train loss 4.07168. lr 2.184000e-04:   7%|▋         | 455/6250 [2:42:42<34:25:06, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 455: train loss 3.69103. lr 2.188800e-04:   7%|▋         | 455/6250 [2:43:04<34:25:06, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 455: train loss 3.69103. lr 2.188800e-04:   7%|▋         | 456/6250 [2:43:04<34:41:07, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 456: train loss 3.94021. lr 2.193600e-04:   7%|▋         | 456/6250 [2:43:25<34:41:07, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 456: train loss 3.94021. lr 2.193600e-04:   7%|▋         | 457/6250 [2:43:25<34:24:18, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 457: train loss 4.04874. lr 2.198400e-04:   7%|▋         | 457/6250 [2:43:46<34:24:18, 21.38s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 457: train loss 4.04874. lr 2.198400e-04:   7%|▋         | 458/6250 [2:43:46<34:27:38, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 458: train loss 3.76468. lr 2.203200e-04:   7%|▋         | 458/6250 [2:44:08<34:27:38, 21.42s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 458: train loss 3.76468. lr 2.203200e-04:   7%|▋         | 459/6250 [2:44:08<34:42:39, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 459: train loss 4.09903. lr 2.208000e-04:   7%|▋         | 459/6250 [2:44:30<34:42:39, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 459: train loss 4.09903. lr 2.208000e-04:   7%|▋         | 460/6250 [2:44:30<34:32:00, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 460: train loss 4.13404. lr 2.212800e-04:   7%|▋         | 460/6250 [2:44:51<34:32:00, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 460: train loss 4.13404. lr 2.212800e-04:   7%|▋         | 461/6250 [2:44:51<34:24:35, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 461: train loss 4.04018. lr 2.217600e-04:   7%|▋         | 461/6250 [2:45:13<34:24:35, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 461: train loss 4.04018. lr 2.217600e-04:   7%|▋         | 462/6250 [2:45:13<34:37:26, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 462: train loss 3.97284. lr 2.222400e-04:   7%|▋         | 462/6250 [2:45:34<34:37:26, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 462: train loss 3.97284. lr 2.222400e-04:   7%|▋         | 463/6250 [2:45:34<34:21:09, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 463: train loss 3.69776. lr 2.227200e-04:   7%|▋         | 463/6250 [2:45:55<34:21:09, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 463: train loss 3.69776. lr 2.227200e-04:   7%|▋         | 464/6250 [2:45:55<34:23:37, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 464: train loss 3.92156. lr 2.232000e-04:   7%|▋         | 464/6250 [2:46:17<34:23:37, 21.40s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 464: train loss 3.92156. lr 2.232000e-04:   7%|▋         | 465/6250 [2:46:17<34:38:30, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 465: train loss 4.09236. lr 2.236800e-04:   7%|▋         | 465/6250 [2:46:38<34:38:30, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 465: train loss 4.09236. lr 2.236800e-04:   7%|▋         | 466/6250 [2:46:38<34:28:17, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 466: train loss 4.09579. lr 2.241600e-04:   7%|▋         | 466/6250 [2:47:00<34:28:17, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 466: train loss 4.09579. lr 2.241600e-04:   7%|▋         | 467/6250 [2:47:00<34:33:23, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 467: train loss 4.05655. lr 2.246400e-04:   7%|▋         | 467/6250 [2:47:22<34:33:23, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 467: train loss 4.05655. lr 2.246400e-04:   7%|▋         | 468/6250 [2:47:22<34:37:22, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 468: train loss 3.92070. lr 2.251200e-04:   7%|▋         | 468/6250 [2:47:43<34:37:22, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 468: train loss 3.92070. lr 2.251200e-04:   8%|▊         | 469/6250 [2:47:43<34:17:46, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 469: train loss 4.01233. lr 2.256000e-04:   8%|▊         | 469/6250 [2:48:05<34:17:46, 21.36s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 469: train loss 4.01233. lr 2.256000e-04:   8%|▊         | 470/6250 [2:48:05<34:35:46, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 470: train loss 3.76909. lr 2.260800e-04:   8%|▊         | 470/6250 [2:48:26<34:35:46, 21.55s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 470: train loss 3.76909. lr 2.260800e-04:   8%|▊         | 471/6250 [2:48:26<34:30:01, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 471: train loss 3.98449. lr 2.265600e-04:   8%|▊         | 471/6250 [2:48:47<34:30:01, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 471: train loss 3.98449. lr 2.265600e-04:   8%|▊         | 472/6250 [2:48:47<34:19:31, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 472: train loss 3.88948. lr 2.270400e-04:   8%|▊         | 472/6250 [2:49:09<34:19:31, 21.39s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 472: train loss 3.88948. lr 2.270400e-04:   8%|▊         | 473/6250 [2:49:09<34:31:36, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 473: train loss 3.84369. lr 2.275200e-04:   8%|▊         | 473/6250 [2:49:30<34:31:36, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 473: train loss 3.84369. lr 2.275200e-04:   8%|▊         | 474/6250 [2:49:30<34:29:05, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 474: train loss 4.16638. lr 2.280000e-04:   8%|▊         | 474/6250 [2:49:52<34:29:05, 21.49s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 474: train loss 4.16638. lr 2.280000e-04:   8%|▊         | 475/6250 [2:49:52<34:32:06, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 475: train loss 3.83829. lr 2.284800e-04:   8%|▊         | 475/6250 [2:50:14<34:32:06, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 475: train loss 3.83829. lr 2.284800e-04:   8%|▊         | 476/6250 [2:50:14<34:43:45, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 476: train loss 3.71407. lr 2.289600e-04:   8%|▊         | 476/6250 [2:50:35<34:43:45, 21.65s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 476: train loss 3.71407. lr 2.289600e-04:   8%|▊         | 477/6250 [2:50:35<34:25:33, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 477: train loss 3.64352. lr 2.294400e-04:   8%|▊         | 477/6250 [2:50:56<34:25:33, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 477: train loss 3.64352. lr 2.294400e-04:   8%|▊         | 478/6250 [2:50:56<34:16:08, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 478: train loss 3.71515. lr 2.299200e-04:   8%|▊         | 478/6250 [2:51:18<34:16:08, 21.37s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 478: train loss 3.71515. lr 2.299200e-04:   8%|▊         | 479/6250 [2:51:18<34:28:27, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 479: train loss 3.79286. lr 2.304000e-04:   8%|▊         | 479/6250 [2:51:40<34:28:27, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 479: train loss 3.79286. lr 2.304000e-04:   8%|▊         | 480/6250 [2:51:40<34:42:39, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 480: train loss 4.01935. lr 2.308800e-04:   8%|▊         | 480/6250 [2:52:01<34:42:39, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 480: train loss 4.01935. lr 2.308800e-04:   8%|▊         | 481/6250 [2:52:01<34:39:21, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 481: train loss 3.65623. lr 2.313600e-04:   8%|▊         | 481/6250 [2:52:23<34:39:21, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 481: train loss 3.65623. lr 2.313600e-04:   8%|▊         | 482/6250 [2:52:23<34:38:54, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 482: train loss 3.82720. lr 2.318400e-04:   8%|▊         | 482/6250 [2:52:44<34:38:54, 21.63s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 482: train loss 3.82720. lr 2.318400e-04:   8%|▊         | 483/6250 [2:52:44<34:30:48, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 483: train loss 3.95816. lr 2.323200e-04:   8%|▊         | 483/6250 [2:53:06<34:30:48, 21.54s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 483: train loss 3.95816. lr 2.323200e-04:   8%|▊         | 484/6250 [2:53:06<34:33:45, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 484: train loss 3.97772. lr 2.328000e-04:   8%|▊         | 484/6250 [2:53:27<34:33:45, 21.58s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 484: train loss 3.97772. lr 2.328000e-04:   8%|▊         | 485/6250 [2:53:27<34:27:34, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 485: train loss 3.95122. lr 2.332800e-04:   8%|▊         | 485/6250 [2:53:49<34:27:34, 21.52s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 485: train loss 3.95122. lr 2.332800e-04:   8%|▊         | 486/6250 [2:53:49<34:22:27, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 486: train loss 3.93413. lr 2.337600e-04:   8%|▊         | 486/6250 [2:54:10<34:22:27, 21.47s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 486: train loss 3.93413. lr 2.337600e-04:   8%|▊         | 487/6250 [2:54:10<34:23:02, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 487: train loss 3.95586. lr 2.342400e-04:   8%|▊         | 487/6250 [2:54:32<34:23:02, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 487: train loss 3.95586. lr 2.342400e-04:   8%|▊         | 488/6250 [2:54:32<34:20:59, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 488: train loss 3.94241. lr 2.347200e-04:   8%|▊         | 488/6250 [2:54:53<34:20:59, 21.46s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 488: train loss 3.94241. lr 2.347200e-04:   8%|▊         | 489/6250 [2:54:53<34:22:12, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 489: train loss 3.90588. lr 2.352000e-04:   8%|▊         | 489/6250 [2:55:15<34:22:12, 21.48s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 489: train loss 3.90588. lr 2.352000e-04:   8%|▊         | 490/6250 [2:55:15<34:35:38, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 490: train loss 3.83313. lr 2.356800e-04:   8%|▊         | 490/6250 [2:55:36<34:35:38, 21.62s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 490: train loss 3.83313. lr 2.356800e-04:   8%|▊         | 491/6250 [2:55:36<34:24:25, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 491: train loss 3.94980. lr 2.361600e-04:   8%|▊         | 491/6250 [2:55:58<34:24:25, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 491: train loss 3.94980. lr 2.361600e-04:   8%|▊         | 492/6250 [2:55:58<34:29:25, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 492: train loss 3.74309. lr 2.366400e-04:   8%|▊         | 492/6250 [2:56:20<34:29:25, 21.56s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 492: train loss 3.74309. lr 2.366400e-04:   8%|▊         | 493/6250 [2:56:20<34:25:57, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 493: train loss 3.77276. lr 2.371200e-04:   8%|▊         | 493/6250 [2:56:41<34:25:57, 21.53s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 493: train loss 3.77276. lr 2.371200e-04:   8%|▊         | 494/6250 [2:56:41<34:23:07, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 494: train loss 3.77250. lr 2.376000e-04:   8%|▊         | 494/6250 [2:57:03<34:23:07, 21.51s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 494: train loss 3.77250. lr 2.376000e-04:   8%|▊         | 495/6250 [2:57:03<34:39:25, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 495: train loss 3.79604. lr 2.380800e-04:   8%|▊         | 495/6250 [2:57:24<34:39:25, 21.68s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 495: train loss 3.79604. lr 2.380800e-04:   8%|▊         | 496/6250 [2:57:24<34:30:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 496: train loss 3.71620. lr 2.385600e-04:   8%|▊         | 496/6250 [2:57:46<34:30:40, 21.59s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 496: train loss 3.71620. lr 2.385600e-04:   8%|▊         | 497/6250 [2:57:46<34:21:22, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 497: train loss 3.77424. lr 2.390400e-04:   8%|▊         | 497/6250 [2:58:08<34:21:22, 21.50s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 497: train loss 3.77424. lr 2.390400e-04:   8%|▊         | 498/6250 [2:58:08<34:36:46, 21.66s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "epoch 1 iter 498: train loss 3.79817. lr 2.395200e-04:   8%|▊         | 498/6250 [2:58:29<34:36:46, 21.66s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Note that Karpathy running on an 8-GPU V100 machine so each GPU has 32GB.\n",
        "He use a batch of 16*8 in the original implementation. I brought this down to 8\n",
        "so it could fit into Kaggle TPU.\n",
        "If you don't have as many computational resources you have to bring down\n",
        "the batch_size until the model fits into your memory, and then you may\n",
        "also need to adjust the learning rate (e.g. decrease it a bit). Alternatively,\n",
        "you can use an even smaller model up above, bringing down the number of layers,\n",
        "number of heads, and the embedding size.\n",
        "\"\"\"\n",
        "\n",
        "tokens_per_epoch = len(train_data) * train_dataset.block_size\n",
        "train_epochs = 20 # todo run a bigger model and longer, this is tiny\n",
        "\n",
        "# initialize a trainer instance and kick off training\n",
        "tconf = TrainerConfig(max_epochs=train_epochs, batch_size=8, learning_rate=3e-3,\n",
        "                      betas = (0.9, 0.95), weight_decay=0,\n",
        "                      lr_decay=True, warmup_tokens=tokens_per_epoch, final_tokens=train_epochs*tokens_per_epoch,\n",
        "                      ckpt_path='cifar10_model.pt',\n",
        "                      num_workers=8)\n",
        "trainer = Trainer(model, train_dataset, test_dataset, tconf)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load the state of the best model we've seen based on early stopping\n",
        "checkpoint = torch.load('cifar10_model.pt')\n",
        "model.load_state_dict(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# to sample we also have to technically \"train\" a separate model for the first token in the sequence\n",
        "# we are going to do so below simply by calculating and normalizing the histogram of the first token\n",
        "counts = torch.ones(ncluster) # start counts as 1 not zero, this is called \"smoothing\"\n",
        "rp = torch.randperm(len(train_dataset))\n",
        "nest = 5000 # how many images to use for the estimation\n",
        "for i in range(nest):\n",
        "    a, _ = train_dataset[int(rp[i])]\n",
        "    t = a[0].item() # index of first token in the sequence\n",
        "    counts[t] += 1\n",
        "prob = counts/counts.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "from mingpt.utils import sample\n",
        "\n",
        "n_samples = 32\n",
        "start_pixel = np.random.choice(np.arange(C.size(0)), size=(n_samples, 1), replace=True, p=prob)\n",
        "start_pixel = torch.from_numpy(start_pixel).to(trainer.device)\n",
        "pixels = sample(model, start_pixel, 32*32-1, temperature=1.0, sample=True, top_k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# for visualization we have to invert the permutation used to produce the pixels\n",
        "iperm = torch.argsort(train_dataset.perm)\n",
        "\n",
        "ncol = 8\n",
        "nrow = n_samples // ncol\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(n_samples):\n",
        "    pxi = pixels[i][iperm] # note: undo the encoding permutation\n",
        "    \n",
        "    plt.subplot(nrow, ncol, i+1)\n",
        "    plt.imshow(C[pxi].view(32, 32, 3).numpy().astype(np.uint8))\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# visualize some of the learned positional embeddings, maybe they contain structure\n",
        "plt.figure(figsize=(5, 5))\n",
        "nsee = 8*8\n",
        "ncol = 8\n",
        "nrow = nsee // ncol\n",
        "for i in range(nsee):\n",
        "    \n",
        "    ci = model.pos_emb.data[0, :, i].cpu()\n",
        "    zci = torch.cat((torch.tensor([0.0]), ci)) # pre-cat a zero\n",
        "    rzci = zci[iperm] # undo the permutation to recover the pixel space of the image\n",
        "    \n",
        "    plt.subplot(nrow, ncol, i+1)\n",
        "    plt.imshow(rzci.view(32, 32).numpy())\n",
        "    plt.axis('off')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "papermill": {
      "duration": null,
      "end_time": null,
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-10-15T08:02:19.332283",
      "version": "2.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
