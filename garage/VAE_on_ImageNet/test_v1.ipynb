{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup, AdamW\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "c_ = Fore.CYAN\n",
    "g_ = Fore.GREEN\n",
    "y_ = Fore.YELLOW\n",
    "m_ = Fore.MAGENTA\n",
    "sr_ = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = {'lr':1e-3,\n",
    "          'wd':1e-2,\n",
    "          'bs':256,\n",
    "          'img_size':128,\n",
    "          'epochs':100,\n",
    "          'seed':1000}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])\n",
    "\n",
    "train_paths = np.random.choice(glob.glob('../input/imagenetmini-1000/imagenet-mini/train/**/*.JPEG'),10000)\n",
    "valid_paths = np.random.choice(glob.glob('../input/imagenetmini-1000/imagenet-mini/val/**/*.JPEG'),1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(config['img_size'],config['img_size'],always_apply=True),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self,paths,augmentations):\n",
    "        self.paths = paths\n",
    "        self.augmentations = augmentations\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        path = self.paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_dataset = ImageNetDataset(valid_paths,augmentations=get_train_transforms())\n",
    "test_dl = DataLoader(test_dataset,batch_size=16,shuffle=False,num_workers=4)\n",
    "\n",
    "dataiter = iter(test_dl)\n",
    "sample = dataiter.next()\n",
    "\n",
    "img = torchvision.utils.make_grid(sample).permute(1,2,0).numpy()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,latent_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.shape = 32\n",
    "\n",
    "        #encode\n",
    "        self.conv1 = nn.Conv2d(3,32,kernel_size=3,stride=2)\n",
    "        self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*(self.shape-1)**2,2*self.latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.scale = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "        #decode\n",
    "        self.fc2 = nn.Linear(self.latent_dim,(self.shape**2) *32)\n",
    "        self.conv3 = nn.ConvTranspose2d(32,64,kernel_size=2,stride=2)\n",
    "        self.conv4 = nn.ConvTranspose2d(64,32,kernel_size=2,stride=2)\n",
    "        self.conv5 = nn.ConvTranspose2d(32,3,kernel_size=1,stride=1)\n",
    "\n",
    "\n",
    "    def encode(self,x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "#         print(x.shape)\n",
    "        x = self.relu(self.flatten(x))\n",
    "        x = self.fc1(x)\n",
    "        mean,logvar = torch.split(x,self.latent_dim,dim=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def decode(self,eps):\n",
    "        x = self.relu(self.fc2(eps))\n",
    "        x = torch.reshape(x,(x.shape[0],32,self.shape,self.shape))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "    def reparamatrize(self,mean,std):\n",
    "        q = torch.distributions.Normal(mean,std)\n",
    "        return q.rsample()\n",
    "\n",
    "    def kl_loss(self,z,mean,std):\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mean),torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mean,torch.exp(std/2))\n",
    "\n",
    "        log_pz = p.log_prob(z)\n",
    "        log_qzx = q.log_prob(z)\n",
    "\n",
    "        kl_loss = (log_qzx - log_pz)\n",
    "        kl_loss = kl_loss.sum(-1)\n",
    "        return kl_loss\n",
    "\n",
    "    def gaussian_likelihood(self,inputs,outputs,scale):\n",
    "        dist = torch.distributions.Normal(outputs,torch.exp(scale))\n",
    "        log_pxz = dist.log_prob(inputs)\n",
    "        return log_pxz.sum(dim=(1,2,3))\n",
    "\n",
    "    def loss_fn(self,inputs,outputs,z,mean,std):\n",
    "        kl_loss = self.kl_loss(z,mean,std)\n",
    "        rec_loss = self.gaussian_likelihood(inputs,outputs,self.scale)\n",
    "\n",
    "        return torch.mean(kl_loss - rec_loss)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        mean,logvar = self.encode(inputs)\n",
    "        std = torch.exp(logvar/2)\n",
    "        z = self.reparamatrize(mean,std)\n",
    "        outputs = self.decode(z)\n",
    "\n",
    "        loss = self.loss_fn(inputs,outputs,z,mean,std)\n",
    "        return loss,(outputs,z,mean,std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run():\n",
    "        \n",
    "    def evaluate(model,valid_loader):\n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, inputs in enumerate(valid_loader):\n",
    "                loss,_ = model(inputs)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        return valid_loss\n",
    "        \n",
    "    def train_and_evaluate_loop(train_loader,valid_loader,model,optimizer,\n",
    "                                epoch,best_loss,lr_scheduler=None):\n",
    "        train_loss = 0\n",
    "        for i, inputs in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            loss,_ = model(inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if lr_scheduler:\n",
    "                lr_scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        valid_loss = evaluate(model,valid_loader) \n",
    "\n",
    "        if valid_loss <= best_loss:\n",
    "            print(f\"Epoch:{epoch} |Train Loss:{train_loss}|Valid Loss:{valid_loss}\")\n",
    "            print(f\"{g_}Loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            torch.save(model.state_dict(),'./imagenet_vae_model.bin')\n",
    "                    \n",
    "        return best_loss\n",
    "        \n",
    "    accelerator = Accelerator()\n",
    "    print(f\"{accelerator.device} is used\")\n",
    "\n",
    "    model = Model()\n",
    "    \n",
    "    ## train\n",
    "    train_dataset = ImageNetDataset(train_paths,augmentations=get_train_transforms())\n",
    "    train_dl = DataLoader(train_dataset,batch_size=config['bs'],shuffle=True,num_workers=4)\n",
    "    \n",
    "    \n",
    "    #valid\n",
    "    valid_dataset = ImageNetDataset(valid_paths,augmentations=get_train_transforms())\n",
    "    valid_dl = DataLoader(valid_dataset,batch_size=config['bs'],shuffle=False,num_workers=4)\n",
    "    \n",
    "      \n",
    "    optimizer = AdamW(model.parameters(),lr=config['lr'],weight_decay=config['wd'])\n",
    "    lr_scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps= config['epochs'] * len(train_dl))\n",
    "\n",
    "    model,train_dl,valid_dl,optimizer,lr_scheduler = accelerator.prepare(model,train_dl,valid_dl,optimizer,lr_scheduler)\n",
    "\n",
    "    best_loss = 9999999\n",
    "    start_time = time.time()\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        print(f\"Epoch Started:{epoch}\")\n",
    "        best_loss = train_and_evaluate_loop(train_dl,valid_dl,model,optimizer,epoch,best_loss,lr_scheduler)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"{m_}Time taken by epoch {epoch} is {end_time-start_time:.2f}s{sr_}\")\n",
    "        start_time = end_time\n",
    "        \n",
    "    return best_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
